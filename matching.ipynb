{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1880,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1881,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.14.0.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly\n",
        "import datapane as dp\n",
        "plotly.offline.init_notebook_mode(connected=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1882,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import pickle\n",
        "\n",
        "import Levenshtein\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upload json files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1883,
      "metadata": {},
      "outputs": [],
      "source": [
        "#files= ['0.json', '1.json', '2.json', '3.json', '4.json','42.json', '15693.json']\n",
        "files = ['sample.json']\n",
        "# create an empty list to store the DataFrames\n",
        "dfsList = [pd.read_json(file, orient='records') for file in files]\n",
        "\n",
        "# combine all DataFrames into a single DataFrame\n",
        "crossrefDF = pd.concat(dfsList, ignore_index=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data preparation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1885,
      "metadata": {},
      "outputs": [],
      "source": [
        "noAuthors = [i for i in range(len(crossrefDF)) if 'author' not in crossrefDF['items'][i]]\n",
        "\n",
        "Authors = [i for i in range(len(crossrefDF)) if 'author'  in crossrefDF['items'][i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1886,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1886,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(noAuthors) + len(Authors) == len(crossrefDF)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rows with authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1887,
      "metadata": {},
      "outputs": [],
      "source": [
        "crossrefAuth = crossrefDF.iloc[Authors].copy()\n",
        "\n",
        "crossrefAuth.reset_index(inplace= True)\n",
        "crossrefAuth.drop(columns = ['index'], inplace = True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract 'DOI', authors --- number of authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1888,
      "metadata": {},
      "outputs": [],
      "source": [
        "crossrefAuth.loc[:, 'DOI'] = crossrefAuth['items'].apply(lambda x: x['DOI'])\n",
        "crossrefAuth.loc[:,'authors'] = crossrefAuth['items'].apply(lambda x: x['author'])\n",
        "\n",
        "numAuthors = [len(crossrefAuth.iloc[i]['authors']) for i in range(len(crossrefAuth))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1893,
      "metadata": {},
      "outputs": [],
      "source": [
        "## yparxoun lathi  ---> kalytera number of affiliations\n",
        "crossrefAuth.loc[:,'# authors'] = numAuthors"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract 'affiliations' --- number of affiliations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1895,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getAff(k):\n",
        "   return [crossrefAuth['authors'][k][j]['affiliation'] for j in range(len(crossrefAuth['authors'][k]))]\n",
        "    \n",
        "Affiliations = [getAff(k) for k in range(len(crossrefAuth))]\n",
        "\n",
        "crossrefAuth.loc[:,'affiliations'] = Affiliations\n",
        "\n",
        "numAffil = [len(Affiliations[i]) for i in range(len(crossrefAuth))]\n",
        "\n",
        "crossrefAuth.loc[:,'# Affil'] = numAffil"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean 'empty' affiliations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1900,
      "metadata": {},
      "outputs": [],
      "source": [
        "possibleEmptyAff = []\n",
        "\n",
        "for k in range(len(crossrefAuth)):\n",
        "    if len(crossrefAuth['affiliations'][k][0]) == 0:\n",
        "        possibleEmptyAff.append(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1901,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "610"
            ]
          },
          "execution_count": 1901,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(possibleEmptyAff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1902,
      "metadata": {},
      "outputs": [],
      "source": [
        "nonEmptyAff = []\n",
        "\n",
        "for k in possibleEmptyAff:\n",
        "    for j in range(len(crossrefAuth['affiliations'].iloc[k])):\n",
        "        if len(crossrefAuth['affiliations'].iloc[k][j]) != 0:\n",
        "            nonEmptyAff.append(k)\n",
        "    \n",
        "FinalEmptyyAff =  [x for x in possibleEmptyAff if x not in nonEmptyAff] \n",
        "FinalNonEmptyAff = [x for x in range(len(crossrefAuth)) if x not in FinalEmptyyAff]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# affilDF: crossrefAuth subdataframe with nonpempty affiliation lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1905,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF = crossrefAuth.iloc[FinalNonEmptyAff].copy()\n",
        "affilDF.reset_index(inplace = True)\n",
        "affilDF.drop(columns = ['index'], inplace = True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (still some cleaning: cases with empty brackets [{}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1906,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>items</th>\n",
              "      <th>DOI</th>\n",
              "      <th>authors</th>\n",
              "      <th># authors</th>\n",
              "      <th>affiliations</th>\n",
              "      <th># Affil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [items, DOI, authors, # authors, affiliations, # Affil]\n",
              "Index: []"
            ]
          },
          "execution_count": 1906,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "affilDF[affilDF['DOI'] == '10.48130/emst-2022-0020']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1907,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in range(len(affilDF)):\n",
        "    if len(affilDF['affiliations'][k][0]) != 0 and affilDF['affiliations'][k][0][0] == {}:\n",
        "        print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1908,
      "metadata": {},
      "outputs": [],
      "source": [
        "emptyBrackets = [k for k in range(len(affilDF)) if len(affilDF['affiliations'][k][0]) != 0 and affilDF['affiliations'][k][0][0] == {}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1909,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>items</th>\n",
              "      <th>DOI</th>\n",
              "      <th>authors</th>\n",
              "      <th># authors</th>\n",
              "      <th>affiliations</th>\n",
              "      <th># Affil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [items, DOI, authors, # authors, affiliations, # Affil]\n",
              "Index: []"
            ]
          },
          "execution_count": 1909,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "affilDF.iloc[emptyBrackets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1910,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>items</th>\n",
              "      <th>DOI</th>\n",
              "      <th>authors</th>\n",
              "      <th># authors</th>\n",
              "      <th>affiliations</th>\n",
              "      <th># Affil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/acsami.2c18...</td>\n",
              "      <td>10.1021/acsami.2c18397</td>\n",
              "      <td>[{'given': 'Guoxian', 'family': 'Zhang', 'sequ...</td>\n",
              "      <td>8</td>\n",
              "      <td>[[{'name': 'Key Laboratory of Special Function...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/acsomega.2c...</td>\n",
              "      <td>10.1021/acsomega.2c04273</td>\n",
              "      <td>[{'given': 'Junlong', 'family': 'Han', 'sequen...</td>\n",
              "      <td>7</td>\n",
              "      <td>[[{'name': 'School of Mechanical Engineering a...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;The article provides a t...</td>\n",
              "      <td>10.54891/2786-7005-2022-1-13</td>\n",
              "      <td>[{'ORCID': 'http://orcid.org/0000-0002-1686-19...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Communal Institution of Higher Edu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.158.8.3587</td>\n",
              "      <td>[{'given': 'S J', 'family': 'Gobin', 'sequence...</td>\n",
              "      <td>4</td>\n",
              "      <td>[[{'name': 'Department of Immunohaematology an...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1061/(asce)0887-...</td>\n",
              "      <td>10.1061/(asce)0887-3828(2002)16:3(98)</td>\n",
              "      <td>[{'given': 'Norbert J.', 'family': 'Delatte', ...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Assistant Professor, Dept. of Civi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;The authors highlight th...</td>\n",
              "      <td>10.4018/978-1-6684-7593-5.ch044</td>\n",
              "      <td>[{'given': 'Renuka', 'family': 'Garg', 'sequen...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Veer Narmad South Gujarat Universi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.159.11.5372</td>\n",
              "      <td>[{'given': 'C J', 'family': 'Howard', 'sequenc...</td>\n",
              "      <td>6</td>\n",
              "      <td>[[{'name': 'The Institute for Animal Health, C...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;: Overcrowding and house...</td>\n",
              "      <td>10.18231/j.jchm.2022.037</td>\n",
              "      <td>[{'given': 'Ravikant Rambhai', 'family': 'Pate...</td>\n",
              "      <td>4</td>\n",
              "      <td>[[], [{'name': 'GMERS Medical College, Valsad,...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.162.12.6967</td>\n",
              "      <td>[{'given': 'Chris A.', 'family': 'Benedict', '...</td>\n",
              "      <td>8</td>\n",
              "      <td>[[{'name': '*Division of Molecular Immunology,...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/jm020002p',...</td>\n",
              "      <td>10.1021/jm020002p</td>\n",
              "      <td>[{'given': 'Rachel A.', 'family': 'Powers', 's...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Department of Molecular Pharmacolo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>278 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 items  \\\n",
              "0    {'URL': 'http://dx.doi.org/10.1021/acsami.2c18...   \n",
              "1    {'URL': 'http://dx.doi.org/10.1021/acsomega.2c...   \n",
              "2    {'abstract': '<jats:p>The article provides a t...   \n",
              "3    {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "4    {'URL': 'http://dx.doi.org/10.1061/(asce)0887-...   \n",
              "..                                                 ...   \n",
              "273  {'abstract': '<jats:p>The authors highlight th...   \n",
              "274  {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "275  {'abstract': '<jats:p>: Overcrowding and house...   \n",
              "276  {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "277  {'URL': 'http://dx.doi.org/10.1021/jm020002p',...   \n",
              "\n",
              "                                       DOI  \\\n",
              "0                   10.1021/acsami.2c18397   \n",
              "1                 10.1021/acsomega.2c04273   \n",
              "2             10.54891/2786-7005-2022-1-13   \n",
              "3              10.4049/jimmunol.158.8.3587   \n",
              "4    10.1061/(asce)0887-3828(2002)16:3(98)   \n",
              "..                                     ...   \n",
              "273        10.4018/978-1-6684-7593-5.ch044   \n",
              "274           10.4049/jimmunol.159.11.5372   \n",
              "275               10.18231/j.jchm.2022.037   \n",
              "276           10.4049/jimmunol.162.12.6967   \n",
              "277                      10.1021/jm020002p   \n",
              "\n",
              "                                               authors  # authors  \\\n",
              "0    [{'given': 'Guoxian', 'family': 'Zhang', 'sequ...          8   \n",
              "1    [{'given': 'Junlong', 'family': 'Han', 'sequen...          7   \n",
              "2    [{'ORCID': 'http://orcid.org/0000-0002-1686-19...          2   \n",
              "3    [{'given': 'S J', 'family': 'Gobin', 'sequence...          4   \n",
              "4    [{'given': 'Norbert J.', 'family': 'Delatte', ...          2   \n",
              "..                                                 ...        ...   \n",
              "273  [{'given': 'Renuka', 'family': 'Garg', 'sequen...          2   \n",
              "274  [{'given': 'C J', 'family': 'Howard', 'sequenc...          6   \n",
              "275  [{'given': 'Ravikant Rambhai', 'family': 'Pate...          4   \n",
              "276  [{'given': 'Chris A.', 'family': 'Benedict', '...          8   \n",
              "277  [{'given': 'Rachel A.', 'family': 'Powers', 's...          2   \n",
              "\n",
              "                                          affiliations  # Affil  \n",
              "0    [[{'name': 'Key Laboratory of Special Function...        8  \n",
              "1    [[{'name': 'School of Mechanical Engineering a...        7  \n",
              "2    [[{'name': 'Communal Institution of Higher Edu...        2  \n",
              "3    [[{'name': 'Department of Immunohaematology an...        4  \n",
              "4    [[{'name': 'Assistant Professor, Dept. of Civi...        2  \n",
              "..                                                 ...      ...  \n",
              "273  [[{'name': 'Veer Narmad South Gujarat Universi...        2  \n",
              "274  [[{'name': 'The Institute for Animal Health, C...        6  \n",
              "275  [[], [{'name': 'GMERS Medical College, Valsad,...        4  \n",
              "276  [[{'name': '*Division of Molecular Immunology,...        8  \n",
              "277  [[{'name': 'Department of Molecular Pharmacolo...        2  \n",
              "\n",
              "[278 rows x 6 columns]"
            ]
          },
          "execution_count": 1910,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "affilDF.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1911,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF.drop(emptyBrackets, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1912,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF.reset_index(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1913,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>items</th>\n",
              "      <th>DOI</th>\n",
              "      <th>authors</th>\n",
              "      <th># authors</th>\n",
              "      <th>affiliations</th>\n",
              "      <th># Affil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/acsami.2c18...</td>\n",
              "      <td>10.1021/acsami.2c18397</td>\n",
              "      <td>[{'given': 'Guoxian', 'family': 'Zhang', 'sequ...</td>\n",
              "      <td>8</td>\n",
              "      <td>[[{'name': 'Key Laboratory of Special Function...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/acsomega.2c...</td>\n",
              "      <td>10.1021/acsomega.2c04273</td>\n",
              "      <td>[{'given': 'Junlong', 'family': 'Han', 'sequen...</td>\n",
              "      <td>7</td>\n",
              "      <td>[[{'name': 'School of Mechanical Engineering a...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;The article provides a t...</td>\n",
              "      <td>10.54891/2786-7005-2022-1-13</td>\n",
              "      <td>[{'ORCID': 'http://orcid.org/0000-0002-1686-19...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Communal Institution of Higher Edu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.158.8.3587</td>\n",
              "      <td>[{'given': 'S J', 'family': 'Gobin', 'sequence...</td>\n",
              "      <td>4</td>\n",
              "      <td>[[{'name': 'Department of Immunohaematology an...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1061/(asce)0887-...</td>\n",
              "      <td>10.1061/(asce)0887-3828(2002)16:3(98)</td>\n",
              "      <td>[{'given': 'Norbert J.', 'family': 'Delatte', ...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Assistant Professor, Dept. of Civi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>273</td>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;The authors highlight th...</td>\n",
              "      <td>10.4018/978-1-6684-7593-5.ch044</td>\n",
              "      <td>[{'given': 'Renuka', 'family': 'Garg', 'sequen...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Veer Narmad South Gujarat Universi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>274</td>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.159.11.5372</td>\n",
              "      <td>[{'given': 'C J', 'family': 'Howard', 'sequenc...</td>\n",
              "      <td>6</td>\n",
              "      <td>[[{'name': 'The Institute for Animal Health, C...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>275</td>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;: Overcrowding and house...</td>\n",
              "      <td>10.18231/j.jchm.2022.037</td>\n",
              "      <td>[{'given': 'Ravikant Rambhai', 'family': 'Pate...</td>\n",
              "      <td>4</td>\n",
              "      <td>[[], [{'name': 'GMERS Medical College, Valsad,...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>276</td>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.162.12.6967</td>\n",
              "      <td>[{'given': 'Chris A.', 'family': 'Benedict', '...</td>\n",
              "      <td>8</td>\n",
              "      <td>[[{'name': '*Division of Molecular Immunology,...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>277</td>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/jm020002p',...</td>\n",
              "      <td>10.1021/jm020002p</td>\n",
              "      <td>[{'given': 'Rachel A.', 'family': 'Powers', 's...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Department of Molecular Pharmacolo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>278 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                                              items  \\\n",
              "0        0  {'URL': 'http://dx.doi.org/10.1021/acsami.2c18...   \n",
              "1        1  {'URL': 'http://dx.doi.org/10.1021/acsomega.2c...   \n",
              "2        2  {'abstract': '<jats:p>The article provides a t...   \n",
              "3        3  {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "4        4  {'URL': 'http://dx.doi.org/10.1061/(asce)0887-...   \n",
              "..     ...                                                ...   \n",
              "273    273  {'abstract': '<jats:p>The authors highlight th...   \n",
              "274    274  {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "275    275  {'abstract': '<jats:p>: Overcrowding and house...   \n",
              "276    276  {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "277    277  {'URL': 'http://dx.doi.org/10.1021/jm020002p',...   \n",
              "\n",
              "                                       DOI  \\\n",
              "0                   10.1021/acsami.2c18397   \n",
              "1                 10.1021/acsomega.2c04273   \n",
              "2             10.54891/2786-7005-2022-1-13   \n",
              "3              10.4049/jimmunol.158.8.3587   \n",
              "4    10.1061/(asce)0887-3828(2002)16:3(98)   \n",
              "..                                     ...   \n",
              "273        10.4018/978-1-6684-7593-5.ch044   \n",
              "274           10.4049/jimmunol.159.11.5372   \n",
              "275               10.18231/j.jchm.2022.037   \n",
              "276           10.4049/jimmunol.162.12.6967   \n",
              "277                      10.1021/jm020002p   \n",
              "\n",
              "                                               authors  # authors  \\\n",
              "0    [{'given': 'Guoxian', 'family': 'Zhang', 'sequ...          8   \n",
              "1    [{'given': 'Junlong', 'family': 'Han', 'sequen...          7   \n",
              "2    [{'ORCID': 'http://orcid.org/0000-0002-1686-19...          2   \n",
              "3    [{'given': 'S J', 'family': 'Gobin', 'sequence...          4   \n",
              "4    [{'given': 'Norbert J.', 'family': 'Delatte', ...          2   \n",
              "..                                                 ...        ...   \n",
              "273  [{'given': 'Renuka', 'family': 'Garg', 'sequen...          2   \n",
              "274  [{'given': 'C J', 'family': 'Howard', 'sequenc...          6   \n",
              "275  [{'given': 'Ravikant Rambhai', 'family': 'Pate...          4   \n",
              "276  [{'given': 'Chris A.', 'family': 'Benedict', '...          8   \n",
              "277  [{'given': 'Rachel A.', 'family': 'Powers', 's...          2   \n",
              "\n",
              "                                          affiliations  # Affil  \n",
              "0    [[{'name': 'Key Laboratory of Special Function...        8  \n",
              "1    [[{'name': 'School of Mechanical Engineering a...        7  \n",
              "2    [[{'name': 'Communal Institution of Higher Edu...        2  \n",
              "3    [[{'name': 'Department of Immunohaematology an...        4  \n",
              "4    [[{'name': 'Assistant Professor, Dept. of Civi...        2  \n",
              "..                                                 ...      ...  \n",
              "273  [[{'name': 'Veer Narmad South Gujarat Universi...        2  \n",
              "274  [[{'name': 'The Institute for Animal Health, C...        6  \n",
              "275  [[], [{'name': 'GMERS Medical College, Valsad,...        4  \n",
              "276  [[{'name': '*Division of Molecular Immunology,...        8  \n",
              "277  [[{'name': 'Department of Molecular Pharmacolo...        2  \n",
              "\n",
              "[278 rows x 7 columns]"
            ]
          },
          "execution_count": 1913,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "affilDF.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1914,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF.drop(columns = ['index'], inplace = True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clean affiliations "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## is_contained(a,b) map : returns true when a is a substring of b "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1915,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_contained(s, w):\n",
        "    words = s.split()  # Split the string 's' into a list of words\n",
        "    for word in words:\n",
        "        if word not in w:  # If a word from 's' is not found in 'w'\n",
        "            return False  # Return False immediately\n",
        "    return True  # If all words from 's' are found in 'w', return True"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. \"Unique\" affiliations --- number of unique affiliations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1916,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error indices: []\n"
          ]
        }
      ],
      "source": [
        "uniqueAff = []\n",
        "error_indices =[] # New list to store error indices\n",
        "for i in range(len(affilDF)):\n",
        "    try:\n",
        "        uniqueAff.append(list(set([x[0] for x in [list(d.values()) for d in [item for sublist in affilDF['affiliations'].iloc[i] for item in sublist if sublist !=[{}]]]])))\n",
        "    except TypeError:\n",
        "        print(\"Error occurred for i =\", i)\n",
        "        error_indices.append(i)  # Save the index where the error occurred\n",
        "    #except IndexError:\n",
        "     #   print(\"IndexError occurred for i =\", i)\n",
        "      #  error_indices.append(i)  # Save the index where the IndexError occurred\n",
        "\n",
        "\n",
        "# Print the error indices\n",
        "print(\"Error indices:\", error_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1917,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF.drop(error_indices, inplace = True)\n",
        "affilDF.reset_index(inplace = True)\n",
        "affilDF.drop(columns = ['index'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1918,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF.loc[:,'uniqueAff'] = uniqueAff\n",
        "\n",
        "numUniqueAff = [len(affilDF['uniqueAff'].iloc[i]) for i in range(len(affilDF))]\n",
        "\n",
        "affilDF.loc[:,'# uniqueAff'] = numUniqueAff"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Remove stop words ['from', 'the']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1921,
      "metadata": {},
      "outputs": [],
      "source": [
        "stopWords = ['from', 'the', 'From', 'The', 'of', 'at', 'de']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1922,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_stop_words(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stopWords]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "\n",
        "# apply the function to the column  affilDF['uniqueAff'] to create column affilDF.loc[:,'uniqueAff1']\n",
        "\n",
        "affilDF.loc[:,'uniqueAff1'] = affilDF['uniqueAff'].apply(lambda x: [remove_stop_words(s) for s in x])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Remove parenthesis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1923,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_parentheses(text):\n",
        "   return re.sub(r'\\([^()]*\\)', '', text)\n",
        "\n",
        "# apply the function to each list element of column affilDF['uniqueAff1'] to remove substrings inside parentheses\n",
        "\n",
        "affilDF.loc[:,'uniqueAff1'] = affilDF['uniqueAff1'].apply(lambda x: [remove_parentheses(s) for s in x])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Remove @#$%characters and umlauts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1924,
      "metadata": {},
      "outputs": [],
      "source": [
        "def replace_umlauts(text):\n",
        "    normalized_text = unicodedata.normalize('NFKD', text)\n",
        "    replaced_text = ''.join(c for c in normalized_text if not unicodedata.combining(c))\n",
        "    return replaced_text\n",
        "\n",
        "affNoSymbols = []\n",
        "\n",
        "for i in range(len(list(affilDF['uniqueAff1']))):\n",
        "    L = list(affilDF['uniqueAff1'])[i]\n",
        "    for j in range(len(L)):\n",
        "        L[j] = re.sub(r'[^\\w\\s,Α-Ωα-ωぁ-んァ-ン一-龯，]', '', L[j])\n",
        "        L[j] = replace_umlauts(L[j])\n",
        "        \n",
        "    affNoSymbols.append(L)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1925,
      "metadata": {},
      "outputs": [],
      "source": [
        "affNoSymbols = [[item for item in inner_list if item != \"inc\"] for inner_list in affNoSymbols]\n",
        "\n",
        "affilDF['uniqueAff1'] = affNoSymbols"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Check 'sub'-affiliations (affiliations that are contained in other affiliations of the same DOI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1927,
      "metadata": {},
      "outputs": [],
      "source": [
        "newAff0 = []\n",
        "\n",
        "for k in range(len(affilDF)):\n",
        "    \n",
        "    L2 = []\n",
        "    for s1 in affilDF['uniqueAff1'].iloc[k]:\n",
        "        is_substring = False\n",
        "        for s2 in affilDF['uniqueAff1'].iloc[k]:\n",
        "            if s1 != s2 and s1 in s2:\n",
        "                is_substring = True\n",
        "                break\n",
        "        if not is_substring:\n",
        "            L2.append(s1)\n",
        "    newAff0.append(L2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1928,
      "metadata": {},
      "outputs": [],
      "source": [
        "newAffList = [list(set(newAff0[k])) for k in range(len(newAff0))]\n",
        "affilDF['uniqueAff2'] = newAffList"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Split strings where ',' or ';' appears    | Apply .lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1930,
      "metadata": {},
      "outputs": [],
      "source": [
        "def substringsDict(string):\n",
        "    split_strings = [re.sub(r'^[\\s.]+|[\\s.]+$', '', s.strip()) for s in re.split(r'[,;]', string)]\n",
        "    dict_string = {}\n",
        "    index = 0\n",
        "\n",
        "    for value in split_strings:\n",
        "        if value:\n",
        "            modified_value = re.sub(r'\\buniversit\\w*', 'universit', value, flags=re.IGNORECASE)\n",
        "            dict_string[index] = modified_value.lower()\n",
        "            index += 1\n",
        "\n",
        "    return dict_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1931,
      "metadata": {},
      "outputs": [],
      "source": [
        "newAffkomma = []\n",
        "\n",
        "for k in range(len(affilDF)):\n",
        "    \n",
        "    new_list = []\n",
        "    for item in affilDF['uniqueAff2'].iloc[k]:\n",
        "        new_list.append(substringsDict(item))\n",
        "\n",
        "\n",
        "    newAffkomma.append(new_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1932,
      "metadata": {},
      "outputs": [],
      "source": [
        "for j in range(len(newAffkomma)):\n",
        "    for y in newAffkomma[j]:\n",
        "        if len(y)>1:\n",
        "            for i in range(len(y)-1):\n",
        "                if is_contained('progr', y[i]) and is_contained('dep', y[i+1]):\n",
        "                    del y[i]\n",
        "                elif (is_contained('assistant', y[i]) or is_contained('researcher', y[i]) or is_contained('phd', y[i]) or is_contained('student', y[i]) or is_contained('section', y[i]) or is_contained('prof', y[i]) or is_contained('director', y[i])) and (not is_contained('school', y[i+1]) or is_contained('univ', y[i+1]) or is_contained('inst', y[i+1]) or is_contained('lab', y[i+1]) or is_contained('fac', y[i+1])):\n",
        "                    del y[i]\n",
        "                elif (is_contained('engineer', y[i]) or is_contained('progr', y[i]) or is_contained('unit', y[i]) or is_contained('lab', y[i]) or is_contained('dep', y[i]) or is_contained('inst', y[i]) or is_contained('hosp', y[i]) or is_contained('school', y[i]) or is_contained('fac', y[i])) and is_contained('univ', y[i+1]):\n",
        "                    del y[i]\n",
        "                elif is_contained('lab', y[i]) and (is_contained('college', y[i+1]) or is_contained('inst', y[i+1]) or is_contained('dep', y[i+1]) or is_contained('school', y[i+1])):\n",
        "                    del y[i]\n",
        "                elif is_contained('dep', y[i]) and (is_contained('college', y[i+1]) or is_contained('inst', y[i+1]) or  is_contained('hosp', y[i+1]) or  is_contained('school', y[i+1]) or  is_contained('fac', y[i+1])):\n",
        "                    del y[i]\n",
        "                elif is_contained('inst', y[i]) and (is_contained('dep', y[i+1]) or is_contained('acad', y[i+1]) or is_contained('hosp', y[i+1]) or is_contained('fac', y[i+1]) or is_contained('cent', y[i+1]) or is_contained('div', y[i+1])):\n",
        "                    del y[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1933,
      "metadata": {},
      "outputs": [],
      "source": [
        "lightAff = []\n",
        "for j in range(len(newAffkomma)):\n",
        "    lightAffj = []\n",
        "    for y in newAffkomma[j]:\n",
        "        lightAffj.append(', '.join(list(y.values())))\n",
        "    lightAff.append(lightAffj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1934,
      "metadata": {},
      "outputs": [],
      "source": [
        "lightAff0 = []\n",
        "\n",
        "for k in range(len(lightAff)):\n",
        "    \n",
        "    L2 = []\n",
        "    for s1 in lightAff[k]:\n",
        "        is_substring = False\n",
        "        for s2 in lightAff[k]:\n",
        "            if s1 != s2 and s1 in s2:\n",
        "                is_substring = True\n",
        "                break\n",
        "        if not is_substring:\n",
        "            L2.append(s1)\n",
        "    lightAff0.append(L2)\n",
        "\n",
        "affilDF['lightAff'] = lightAff0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1936,
      "metadata": {},
      "outputs": [],
      "source": [
        "removeList = ['university','research institute','laboratory' , 'universit','gmbh', 'inc', 'university of', 'research center', \n",
        "'university college','national institute of', 'school of medicine', \"university school\", 'graduate school of', 'graduate school of engineering', \n",
        "'institute of tropical medicine', 'institute of virology', 'faculty of medicine','laboratory', 'university park', 'institute of science','Polytechnic University']\n",
        "\n",
        "city_names = [\"Aberdeen\", \"Abilene\", \"Akron\", \"Albany\", \"Albuquerque\", \"Alexandria\", \"Allentown\", \"Amarillo\", \"Anaheim\", \"Anchorage\", \"Ann Arbor\", \"Antioch\", \"Apple Valley\", \"Appleton\", \"Arlington\", \"Arvada\", \"Asheville\", \"Athens\", \"Atlanta\", \"Atlantic City\", \"Augusta\", \"Aurora\", \"Austin\", \"Bakersfield\", \"Baltimore\", \"Barnstable\", \"Baton Rouge\", \"Beaumont\", \"Bel Air\", \"Bellevue\", \"Berkeley\", \"Bethlehem\", \"Billings\", \"Birmingham\", \"Bloomington\", \"Boise\", \"Boise City\", \"Bonita Springs\", \"Boston\", \"Boulder\", \"Bradenton\", \"Bremerton\", \"Bridgeport\", \"Brighton\", \"Brownsville\", \"Bryan\", \"Buffalo\", \"Burbank\", \"Burlington\", \"Cambridge\", \"Canton\", \"Cape Coral\", \"Carrollton\", \"Cary\", \"Cathedral City\", \"Cedar Rapids\", \"Champaign\", \"Chandler\", \"Charleston\", \"Charlotte\", \"Chattanooga\", \"Chesapeake\", \"Chicago\", \"Chula Vista\", \"Cincinnati\", \"Clarke County\", \"Clarksville\", \"Clearwater\", \"Cleveland\", \"College Station\", \"Colorado Springs\", \"Columbia\", \"Columbus\", \"Concord\", \"Coral Springs\", \"Corona\", \"Corpus Christi\", \"Costa Mesa\", \"Dallas\", \"Daly City\", \"Danbury\", \"Davenport\", \"Davidson County\", \"Dayton\", \"Daytona Beach\", \"Deltona\", \"Denton\", \"Denver\", \"Des Moines\", \"Detroit\", \"Downey\", \"Duluth\", \"Durham\", \"El Monte\", \"El Paso\", \"Elizabeth\", \"Elk Grove\", \"Elkhart\", \"Erie\", \"Escondido\", \"Eugene\", \"Evansville\", \"Fairfield\", \"Fargo\", \"Fayetteville\", \"Fitchburg\", \"Flint\", \"Fontana\", \"Fort Collins\", \"Fort Lauderdale\", \"Fort Smith\", \"Fort Walton Beach\", \"Fort Wayne\", \"Fort Worth\", \"Frederick\", \"Fremont\", \"Fresno\", \"Fullerton\", \"Gainesville\", \"Garden Grove\", \"Garland\", \"Gastonia\", \"Gilbert\", \"Glendale\", \"Grand Prairie\", \"Grand Rapids\", \"Grayslake\", \"Green Bay\", \"GreenBay\", \"Greensboro\", \"Greenville\", \"Gulfport-Biloxi\", \"Hagerstown\", \"Hampton\", \"Harlingen\", \"Harrisburg\", \"Hartford\", \"Havre de Grace\", \"Hayward\", \"Hemet\", \"Henderson\", \"Hesperia\", \"Hialeah\", \"Hickory\", \"High Point\", \"Hollywood\", \"Honolulu\", \"Houma\", \"Houston\", \"Howell\", \"Huntington\", \"Huntington Beach\", \"Huntsville\", \"Independence\", \"Indianapolis\", \"Inglewood\", \"Irvine\", \"Irving\", \"Jackson\", \"Jacksonville\", \"Jefferson\", \"Jersey City\", \"Johnson City\", \"Joliet\", \"Kailua\", \"Kalamazoo\", \"Kaneohe\", \"Kansas City\", \"Kennewick\", \"Kenosha\", \"Killeen\", \"Kissimmee\", \"Knoxville\", \"Lacey\", \"Lafayette\", \"Lake Charles\", \"Lakeland\", \"Lakewood\", \"Lancaster\", \"Lansing\", \"Laredo\", \"Las Cruces\", \"Las Vegas\", \"Layton\", \"Leominster\", \"Lewisville\", \"Lexington\", \"Lincoln\", \"Little Rock\", \"Long Beach\", \"Lorain\", \"Los Angeles\", \"Louisville\", \"Lowell\", \"Lubbock\", \"Macon\", \"Madison\", \"Manchester\", \"Marina\", \"Marysville\", \"McAllen\", \"McHenry\", \"Medford\", \"Melbourne\", \"Memphis\", \"Merced\", \"Mesa\", \"Mesquite\", \"Miami\", \"Milwaukee\", \"Minneapolis\", \"Miramar\", \"Mission Viejo\", \"Mobile\", \"Modesto\", \"Monroe\", \"Monterey\", \"Montgomery\", \"Moreno Valley\", \"Murfreesboro\", \"Murrieta\", \"Muskegon\", \"Myrtle Beach\", \"Naperville\", \"Naples\", \"Nashua\", \"Nashville\", \"New Bedford\", \"New Haven\", \"New London\", \"New Orleans\", \"New York\", \"New York City\", \"Newark\", \"Newburgh\", \"Newport News\", \"Norfolk\", \"Normal\", \"Norman\", \"North Charleston\", \"North Las Vegas\", \"North Port\", \"Norwalk\", \"Norwich\", \"Oakland\", \"Ocala\", \"Oceanside\", \"Odessa\", \"Ogden\", \"Oklahoma City\", \"Olathe\", \"Olympia\", \"Omaha\", \"Ontario\", \"Orange\", \"Orem\", \"Orlando\", \"Overland Park\", \"Oxnard\", \"Palm Bay\", \"Palm Springs\", \"Palmdale\", \"Panama City\", \"Pasadena\", \"Paterson\", \"Pembroke Pines\", \"Pensacola\", \"Peoria\", \"Philadelphia\", \"Phoenix\", \"Pittsburgh\", \"Plano\", \"Pomona\", \"Pompano Beach\", \"Port Arthur\", \"Port Orange\", \"Port Saint Lucie\", \"Port St. Lucie\", \"Portland\", \"Portsmouth\", \"Poughkeepsie\", \"Providence\", \"Provo\", \"Pueblo\", \"Punta Gorda\", \"Racine\", \"Raleigh\", \"Rancho Cucamonga\", \"Reading\", \"Redding\", \"Reno\", \"Richland\", \"Richmond\", \"Richmond County\", \"Riverside\", \"Roanoke\", \"Rochester\", \"Rockford\", \"Roseville\", \"Round Lake Beach\", \"Sacramento\", \"Saginaw\", \"Saint Louis\", \"Saint Paul\", \"Saint Petersburg\", \"Salem\", \"Salinas\", \"Salt Lake City\", \"San Antonio\", \"San Bernardino\", \"San Buenaventura\", \"San Diego\", \"San Francisco\", \"San Jose\", \"Santa Ana\", \"Santa Barbara\", \"Santa Clara\", \"Santa Clarita\", \"Santa Cruz\", \"Santa Maria\", \"Santa Rosa\", \"Sarasota\", \"Savannah\", \"Scottsdale\", \"Scranton\", \"Seaside\", \"Seattle\", \"Sebastian\", \"Shreveport\", \"Simi Valley\", \"Sioux City\", \"Sioux Falls\", \"South Bend\", \"South Lyon\", \"Spartanburg\", \"Spokane\", \"Springdale\", \"Springfield\", \"St. Louis\", \"St. Paul\", \"St. Petersburg\", \"Stamford\", \"Sterling Heights\", \"Stockton\", \"Sunnyvale\", \"Syracuse\", \"Tacoma\", \"Tallahassee\", \"Tampa\", \"Temecula\", \"Tempe\", \"Thornton\", \"Thousand Oaks\", \"Toledo\", \"Topeka\", \"Torrance\", \"Trenton\", \"Tucson\", \"Tulsa\", \"Tuscaloosa\", \"Tyler\", \"Utica\", \"Vallejo\", \"Vancouver\", \"Vero Beach\", \"Victorville\", \"Virginia Beach\", \"Visalia\", \"Waco\", \"Warren\", \"Washington\", \"Waterbury\", \"Waterloo\", \"West Covina\", \"West Valley City\", \"Westminster\", \"Wichita\", \"Wilmington\", \"Winston\", \"Winter Haven\", \"Worcester\", \"Yakima\", \"Yonkers\", \"York\", \"Youngstown\"]\n",
        "\n",
        "city_names = [x.lower() for x in city_names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1937,
      "metadata": {},
      "outputs": [],
      "source": [
        "for j in range(len(newAffkomma)):\n",
        "    for y in newAffkomma[j]:\n",
        "        for i in list(y.keys()):\n",
        "\n",
        "            if y[i] in city_names+removeList:\n",
        "                del y[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1938,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF['uniqueAff4'] =  [[list(d.values()) for d in sublist] for sublist in newAffkomma]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Labels based on legalnames of openAIRE's organizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1939,
      "metadata": {},
      "outputs": [],
      "source": [
        "uniList = ['escuela','institu', 'istituto','univ', 'college', 'center', 'centre' , 'cnrs', 'faculty','school' , 'academy' , 'école', 'hochschule' , 'ecole' ]\n",
        "\n",
        "labList = ['lab']\n",
        "\n",
        "hosplList = ['hospital' ,'clinic', 'hôpital']\n",
        "\n",
        "gmbhList = ['gmbh', 'company' , 'industr', 'etaireia' , 'corporation', 'inc']\n",
        "\n",
        "musList =  ['museum', 'library']\n",
        "\n",
        "foundList =  ['foundation' , 'association','organization' ,'society', 'group' ]\n",
        "\n",
        "deptList = ['district' , 'federation'  , 'government' , 'municipal' , 'county','council', 'agency']\n",
        "# miistry -> out\n",
        "\n",
        "unknownList = ['unknown']\n",
        "\n",
        "#######   Dictionaries ##########\n",
        "\n",
        "uniDict = {k: 'Univ/Inst' for k in uniList}   \n",
        "\n",
        "labDict = {k: 'Laboratory' for k in labList} \n",
        "\n",
        "hosplDict = {k: 'Hospital' for k in hosplList}   \n",
        "\n",
        "gmbhDict = {k: 'Company' for k in gmbhList}   \n",
        "\n",
        "musDict = {k: 'Museum' for k in musList}   \n",
        "\n",
        "#schoolDict = {k: 'School' for k in schoolList}   \n",
        "\n",
        "foundDict = {k: 'Foundation' for k in foundList}   \n",
        "\n",
        "deptDict = {k: 'Government' for k in deptList}   \n",
        "\n",
        "unknownDict =  {k: 'Unknown' for k in unknownList}   \n",
        "\n",
        "categDictsList = [uniDict, labDict, hosplDict, gmbhDict, musDict, #schoolDict, \n",
        "                  foundDict, deptDict, unknownDict]\n",
        "\n",
        "################# Final Dictionary #####################\n",
        "\n",
        "categDicts = {}\n",
        "i = 0\n",
        "while i in range(len(categDictsList)):\n",
        "    categDicts.update(categDictsList[i])\n",
        "    i = i+1\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## affiliationsDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1940,
      "metadata": {},
      "outputs": [],
      "source": [
        "affiliationsDict = {}\n",
        "\n",
        "for i in range(len(affilDF)):\n",
        "    affiliationsDict[i] = affilDF['uniqueAff4'].iloc[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1941,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_new = {}\n",
        "\n",
        "# iterate over the keys of affiliationsDict\n",
        "for k in range(len(affiliationsDict)):\n",
        "    mappedk = []\n",
        "    # get the list associated with the current key in affiliationsDict\n",
        "    L = affiliationsDict.get(k, [])\n",
        "    \n",
        "    for x in L:\n",
        "        mapped_listx = [[s, v] for s in x for k2, v in categDicts.items() if k2 in s]\n",
        "        mappedk.append(mapped_listx)\n",
        "    \n",
        "    # add the mapped list to the new dictionary d_new\n",
        "    d_new[k] = mappedk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1942,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF['Dictionary'] = d_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1943,
      "metadata": {},
      "outputs": [],
      "source": [
        "notInList = [i for i in range(len(affilDF)) if affilDF['Dictionary'].iloc[i] == [[]]]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1944,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "266"
            ]
          },
          "execution_count": 1944,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(affilDF)  - len(notInList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1945,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 1945,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(notInList)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# affilDF1 ['DOI', 'affiliations', 'Dictionary','uniqueAff4', 'uniqueAff2','# authors','# uniqueAff']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1947,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF1 = affilDF[['DOI', 'affiliations','lightAff','Dictionary','uniqueAff4', 'uniqueAff2','# authors','# uniqueAff']]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## New column: category based on the labels "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1950,
      "metadata": {},
      "outputs": [],
      "source": [
        "category = [', '.join(list(set([x[1] for y in affilDF1['Dictionary'].iloc[i] for x in y]))) for i in range(len(affilDF1))]\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1951,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF1 = affilDF1.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1952,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF1.loc[:, 'category'] = category\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### new label: rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1953,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(affilDF1)):\n",
        "    if affilDF1['category'].iloc[i] == '':\n",
        "        affilDF1.iloc[i, affilDF1.columns.get_loc('category')] = 'Rest'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1954,
      "metadata": {},
      "outputs": [],
      "source": [
        "affiliationsSimple = [\n",
        "    list(set([inner_list[0] for outer_list in affilDF1['Dictionary'].iloc[i] for inner_list in outer_list]))\n",
        "    for i in range(len(affilDF1))\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1955,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF1.loc[:,'affilSimple'] = affiliationsSimple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1956,
      "metadata": {},
      "outputs": [],
      "source": [
        "def strRadiusU(string):\n",
        "    string = string.lower()\n",
        "    radius = 3\n",
        "    \n",
        "    strList = string.split()\n",
        "    indices = []\n",
        "    result = []\n",
        "\n",
        "    for i, x in enumerate(strList):\n",
        "        if is_contained('univers',x):\n",
        "            indices.append(i)\n",
        "            \n",
        "    for r0 in indices:\n",
        "        lmin =max(0,r0-radius)\n",
        "        lmax =min(r0+radius, len(strList))\n",
        "        s = strList[lmin:lmax]\n",
        "        \n",
        "        result.append(' '.join(s))\n",
        "    \n",
        "    return result "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1957,
      "metadata": {},
      "outputs": [],
      "source": [
        "def strRadiusH(string):\n",
        "    string = string.lower()\n",
        "    radius = 3\n",
        "    \n",
        "    strList = string.split()\n",
        "    indices = []\n",
        "    result = []\n",
        "\n",
        "    for i, x in enumerate(strList):\n",
        "        if is_contained('hospital',x):\n",
        "            indices.append(i)\n",
        "            \n",
        "    for r0 in indices:\n",
        "        lmin =max(0,r0-radius-1)\n",
        "        lmax =min(r0+radius, len(strList))\n",
        "        s = strList[lmin:lmax]\n",
        "        \n",
        "        result.append(' '.join(s))\n",
        "    \n",
        "    return result "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1958,
      "metadata": {},
      "outputs": [],
      "source": [
        "affiliationsSimpleN = []\n",
        "\n",
        "for i in range(len(affiliationsSimple)):\n",
        "    inner = []\n",
        "    for str in affiliationsSimple[i]:\n",
        "        if 'university' in str.split():\n",
        "            for x in strRadiusU(str):\n",
        "                inner.append(x)\n",
        "        elif 'hospital' in str.split():\n",
        "            for x in strRadiusH(str):\n",
        "                inner.append(x)\n",
        "        else:\n",
        "            inner.append(str)\n",
        "    \n",
        "    affiliationsSimpleN.append(inner)      \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1959,
      "metadata": {},
      "outputs": [],
      "source": [
        "affilDF1.loc[:,'affilSimpleNew'] = affiliationsSimpleN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1960,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 1960,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(affilDF1[affilDF1['category'] == 'Rest'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UNIVS & LABS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1961,
      "metadata": {},
      "outputs": [],
      "source": [
        "univLabs = [i for i in range(len(affilDF1)) if 'Laboratory' in affilDF1['category'].iloc[i] \n",
        "            or 'Univ/Inst' in  affilDF1['category'].iloc[i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1962,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "univLabsDF = affilDF1.iloc[univLabs].copy()\n",
        "univLabsDF.reset_index(inplace = True)\n",
        "univLabsDF.drop(columns = ['index'], inplace = True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load files from openAIRE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1965,
      "metadata": {},
      "outputs": [],
      "source": [
        "#with open('dixOpenAIRE_Alletc.pkl', 'rb') as f:\n",
        "#    dixOpenAIRE_Alletc = pickle.load(f)\n",
        "\n",
        "#with open('dixOpenAIRE_id.pkl', 'rb') as f:\n",
        "#    dixOpenAIRE_id = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1966,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('dixOpenOrgId.pkl', 'rb') as f:\n",
        "    dixOpenOrgId = pickle.load(f)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean/modify the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1967,
      "metadata": {},
      "outputs": [],
      "source": [
        "#dixOpenAIRE_Alletc1 =  {k.replace(',', ''): v for k, v in dixOpenAIRE_Alletc.items()}\n",
        "#dixOpenAIRE_id1 = {k.replace(',', ''): v for k, v in dixOpenAIRE_id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1968,
      "metadata": {},
      "outputs": [],
      "source": [
        "dixOpenOrgId1 = {k.replace(',', ''): v for k, v in dixOpenOrgId.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1969,
      "metadata": {},
      "outputs": [],
      "source": [
        "dixOpenOrgId1 = {\n",
        "    replace_umlauts(key): value\n",
        "    for key, value in dixOpenOrgId1.items()\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1970,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_key(key):\n",
        "    # Remove all non-alphanumeric characters except Greek letters and Chinese characters\n",
        "    modified_key = re.sub(r'[^\\w\\s,Α-Ωα-ωぁ-んァ-ン一-龯，]', '', key)\n",
        "    modified_key = re.sub(r'\\buniversit\\w*', 'universit', modified_key, flags=re.IGNORECASE)\n",
        "    return modified_key\n",
        "\n",
        "    \n",
        "def filter_dictionary_keys(dictionary):\n",
        "    filtered_dict = {}\n",
        "    for key, value in dictionary.items():\n",
        "        filtered_key = filter_key(key)\n",
        "        filtered_dict[filtered_key] = value\n",
        "    return filtered_dict\n",
        "\n",
        "\n",
        "#dixOpenAIRE_Alletc1 = filter_dictionary_keys(dixOpenAIRE_Alletc1)\n",
        "#dixOpenAIRE_id1 = filter_dictionary_keys(dixOpenAIRE_id1)\n",
        "dixOpenOrgId1 = filter_dictionary_keys(dixOpenOrgId1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1971,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "dixOpenOrgId2 = {}\n",
        "for key, value in dixOpenOrgId1.items():\n",
        "    updated_key = ' '.join([word for word in key.split() if word.lower() not in ['of', 'at', \"the\", 'de']])\n",
        "    dixOpenOrgId2[updated_key] = value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1972,
      "metadata": {},
      "outputs": [],
      "source": [
        "#del dixOpenAIRE_Alletc1['laboratory']\n",
        "#del dixOpenAIRE_Alletc1['university hospital']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1973,
      "metadata": {},
      "outputs": [],
      "source": [
        "#del dixOpenAIRE_id1['laboratory']\n",
        "#del dixOpenAIRE_id1['university hospital']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1974,
      "metadata": {},
      "outputs": [],
      "source": [
        "del dixOpenOrgId2['universit hospital']\n",
        "del dixOpenOrgId2['universit school']\n",
        "del dixOpenOrgId2['us']\n",
        "del dixOpenOrgId2['ni universit']\n",
        "del dixOpenOrgId2['s v universit']\n",
        "del dixOpenOrgId2['k l universit']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1979,
      "metadata": {},
      "outputs": [],
      "source": [
        "def findID(name):\n",
        "    lnames = []\n",
        "    for x in list(dixOpenOrgId2.keys()):\n",
        "        if name.lower() in x:\n",
        "            lnames.append(x)\n",
        "    return lnames"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MATCHINGS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clean the matchings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1980,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bestSimScore(l1, l2, l3, l4, simU, simG):\n",
        "    \"\"\"\n",
        "    Finds the best match between a 'key word' and several legal names from the OpenAIRE database.\n",
        "    ---> corrects special cases in the main map that follows\n",
        "\n",
        "    Args:\n",
        "        l1: List of light affiliations.\n",
        "        l2: number of candidates.\n",
        "        l3: List of pairs.\n",
        "        l4: mult\n",
        "\n",
        "    Returns:\n",
        "        List: Resulting list containing OpenAIRE names and their similarity scores.\n",
        "    \"\"\"\n",
        "    \n",
        "    vectorizer = CountVectorizer()\n",
        "    numUniv = sum([(l1[i].lower()).count('univ') for i in range(len(l1))])\n",
        "    result = []\n",
        "    for i in range(len(l1)):\n",
        "        best = [] \n",
        "        s = l1[i]\n",
        "       # s_contains_university = is_contained(\"university\", s.lower())  \n",
        "        \n",
        "       # if not is_contained(\"univ\", s.lower()):\n",
        "       #     continue  # Skip if s does not contain \"university\" or \"univ\"\n",
        "        \n",
        "    \n",
        "        for j in range(len(l3)):\n",
        "            x = l3[j][1] \n",
        "           \n",
        "            if [x, l3[j][2]] in result:\n",
        "                    continue\n",
        "            \n",
        "            if l4[l3[j][0]] == 1:\n",
        "               \n",
        "                if  is_contained('univ', x.lower()) and  l3[j][2]> simU:\n",
        "                    result.append([x, l3[j][2]])\n",
        "                elif  l3[j][2] >simG:\n",
        "                    result.append([x, l3[j][2]])\n",
        "\n",
        "                \n",
        "              \n",
        "            elif l3[j][2] >=0.99 and (is_contained(\"univ\", x.lower()) or is_contained(\"college\", x.lower()) or  is_contained(\"center\", x.lower()) or  is_contained(\"schule\", x.lower())): # If the similarity score of a pair (s,x) was 1, we store it to results list\n",
        "                result.append([l3[j][1], 1])\n",
        "                \n",
        "            else:\n",
        "        #        x_contains_university = is_contained(\"university\", x.lower())\n",
        "                if not is_contained(\"univ\", x.lower()):\n",
        "                    continue  # Skip if x does not contain \"university\" or \"univ\"\n",
        "                \n",
        "                if (is_contained('hosp', x.lower()) and not is_contained('hosp', s)) or (not is_contained('hosp', x.lower()) and is_contained('hosp', s)):\n",
        "                    continue\n",
        "                s_vector = vectorizer.fit_transform([s]).toarray() #Else we compute the similarity of s with the original affiiation name\n",
        "                x_vector = vectorizer.transform([x]).toarray()\n",
        "              #  s_vector1 =  vectorizer.transform([s]).toarray()\n",
        "              #  x_vector1 =  vectorizer.fit_transform([s]).toarray()\n",
        "                \n",
        "\n",
        "                # Compute similarity between the vectors\n",
        "                similarity = cosine_similarity(x_vector, s_vector)[0][0]\n",
        "                if similarity> 0.31:\n",
        "               # similarity1 = cosine_similarity(x_vector1, s_vector1)[0][0]\n",
        "                #similarity2 = Levenshtein.ratio(s,x)\n",
        "\n",
        "\n",
        "                    best.append([x, similarity])#(similarity+similarity2)/2])\n",
        "        \n",
        "        if best:\n",
        "            max_numbers = defaultdict(float)\n",
        "            for item in best:\n",
        "                string, number = item\n",
        "                max_numbers[string] = max(max_numbers[string], number)\n",
        "\n",
        "# Create a new list with the elements having the maximum number for each string\n",
        "            reduced_best = [[string, number] for string, number in best if number == max_numbers[string]]\n",
        "\n",
        "#            max_score = max(best, key=lambda x: x[1])[1]\n",
        "#            max_results = [(x[0], x[1]) for x in best if x[1] == max_score]\n",
        "           # if len(reduced_best) > 1:\n",
        "            reduced_best.sort(key=lambda x: x[1], reverse=True)\n",
        "            #reduced_best.sort(key=lambda x: (l2.index(x[0]), -x[1]), reverse=False)\n",
        "           #     result.append(reduced_best[-1])\n",
        "            #else:\n",
        "            result = result + reduced_best\n",
        "                \n",
        "    univ_list = []\n",
        "    other_list = []\n",
        "    \n",
        "    for r in result:\n",
        "        if is_contained('univ',r[0]):\n",
        "            univ_list.append(r)\n",
        "        else:\n",
        "            other_list.append(r)\n",
        "    \n",
        "    limit =  min(numUniv, l2)\n",
        "\n",
        "    if len(univ_list)> limit:\n",
        "        result = univ_list[:limit] + other_list\n",
        "                \n",
        "    return result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Find rows with multiple mathcings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1981,
      "metadata": {},
      "outputs": [],
      "source": [
        "def index_multipleMatchings(df):\n",
        "    multipleMatchings = []\n",
        "    mult = []\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        result_dict = {}\n",
        "        \n",
        "\n",
        "        for t in [t[0] for t in df.Pairs.iloc[i]]:\n",
        "            key = t\n",
        "            if key in result_dict:\n",
        "                result_dict[key] += 1\n",
        "                multipleMatchings.append(i)\n",
        "                \n",
        "            else:\n",
        "                result_dict[key] = 1\n",
        "        mult.append(result_dict)\n",
        "    return [list(set(multipleMatchings)), mult]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1982,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Doi_Ids(m, DF, dixOpenAIRE, simU, simG):\n",
        "    \n",
        "    \"\"\"\n",
        "    Matches affiliations in DataFrame 'DF' with names from dictionary 'dixOpenAIRE' and their openAIRE ids based on similarity scores.\n",
        "\n",
        "    Args:\n",
        "        m (int): The number of DOIs to check.\n",
        "        DF (DataFrame): The input DataFrame containing affiliation data.\n",
        "        dixOpenAIRE (dict): A dictionary of names from OpenAIRE.\n",
        "        simU (float): Similarity threshold for universities.\n",
        "        simG (float): Similarity threshold for non-universities.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: The final DataFrame with matched affiliations and their corresponding similarity scores.\n",
        "    \"\"\"\n",
        "    \n",
        "    lnamelist = list(dixOpenAIRE.keys())\n",
        "    dix = {}    # will store indeces and legalnames of organizations of the DOI { i : [legalname1, legalname2,...]}\n",
        "    deiktes = []  # stores indeces where a match is found\n",
        "    vectorizer = CountVectorizer()\n",
        "    similarity_ab = [] # stores lists of similarity scores of the mathces \n",
        "    pairs = [] #  pairs[i] =  [ [s,x,t] ] where (s,x) is a match and t the corresponding similarity score\n",
        "    \n",
        "    for k in range(m):\n",
        "        similar_k = []\n",
        "        pairs_k = []\n",
        "\n",
        "\n",
        "        for s in DF['affilSimpleNew'].iloc[k]:\n",
        "\n",
        "            if s in lnamelist:\n",
        "                deiktes.append(k)\n",
        "                similarity = 1\n",
        "                similar_k.append(similarity)\n",
        "                \n",
        "                pairs_k.append((s,s,similarity))\n",
        "\n",
        "                if k not in dix:\n",
        "                    dix[k] = [s]\n",
        "                else:\n",
        "                    dix[k].append(s)\n",
        "            else:\n",
        "\n",
        "                for x in lnamelist:\n",
        "                    \n",
        "                    if  is_contained(s, x):\n",
        "                        x_vector = vectorizer.fit_transform([x]).toarray()\n",
        "                        s_vector = vectorizer.transform([s]).toarray()\n",
        "\n",
        "                        # Compute similarity between the vectors\n",
        "                        similarity = cosine_similarity(x_vector, s_vector)[0][0]\n",
        "                        if similarity > min(simU, simG):\n",
        "                            if (is_contained('univ', s) and is_contained('univ', x)) and similarity > simU:\n",
        "                                similar_k.append(similarity)\n",
        "                                deiktes.append(k)\n",
        "                                pairs_k.append((s,x,similarity))\n",
        "\n",
        "                                if k not in dix:\n",
        "                                    dix[k] = [x]\n",
        "                                else:\n",
        "                                    dix[k].append(x)\n",
        "                            elif (not is_contained('univ', s) and not is_contained('univ', x)) and similarity > simG:\n",
        "                                similar_k.append(similarity)\n",
        "                                deiktes.append(k)\n",
        "                                pairs_k.append((s,x,similarity))\n",
        "\n",
        "                                if k not in dix:\n",
        "                                    dix[k] = [x]\n",
        "                                else:\n",
        "                                    dix[k].append(x)\n",
        "                    elif is_contained(x, s):\n",
        "                        if (is_contained('univ', s) and is_contained('univ', x)):\n",
        "\n",
        "                            if 'and' in s:\n",
        "                                list_s = s.split(' and ')\n",
        "                                for t in list_s:\n",
        "                                    if is_contained(x, t) and is_contained('univ', t):\n",
        "                                        t_vector = vectorizer.fit_transform([t]).toarray()\n",
        "                                        x_vector = vectorizer.transform([x]).toarray()\n",
        "\n",
        "                            # Compute similarity between the vectors\n",
        "                                        similarity = cosine_similarity(t_vector, x_vector)[0][0]\n",
        "                                        if similarity > simU:\n",
        "                                            similar_k.append(similarity)\n",
        "                                            deiktes.append(k)\n",
        "                                            pairs_k.append((s,x,similarity))\n",
        "\n",
        "                                            if k not in dix:\n",
        "                                                dix[k] = [x]\n",
        "                                            else:\n",
        "                                                dix[k].append(x)\n",
        "                            \n",
        "                            else: \n",
        "                                s_vector = vectorizer.fit_transform([s]).toarray()\n",
        "                                x_vector = vectorizer.transform([x]).toarray()\n",
        "\n",
        "                                # Compute similarity between the vectors\n",
        "                                similarity = cosine_similarity(s_vector, x_vector)[0][0]\n",
        "                                if similarity > simU: #max(0.82,sim):\n",
        "                                    similar_k.append(similarity)\n",
        "                                    deiktes.append(k)\n",
        "                                    pairs_k.append((s,x,similarity))\n",
        "\n",
        "                                    if k not in dix:\n",
        "                                        dix[k] = [x]\n",
        "                                    else:\n",
        "                                        dix[k].append(x)\n",
        "                        elif not is_contained('univ', s) and not is_contained('univ', x):\n",
        "                            if 'and' in s:\n",
        "                                list_s = s.split(' and ')\n",
        "                                for t in list_s:\n",
        "                                    if is_contained(x, t):\n",
        "                                        t_vector = vectorizer.fit_transform([t]).toarray()\n",
        "                                        x_vector = vectorizer.transform([x]).toarray()\n",
        "\n",
        "                            # Compute similarity between the vectors\n",
        "                                        similarity = cosine_similarity(t_vector, x_vector)[0][0]\n",
        "                                        if similarity > simG:\n",
        "                                            similar_k.append(similarity)\n",
        "                                            deiktes.append(k)\n",
        "                                            pairs_k.append((s,x,similarity))\n",
        "\n",
        "                                            if k not in dix:\n",
        "                                                dix[k] = [x]\n",
        "                                            else:\n",
        "                                                dix[k].append(x)\n",
        "                            \n",
        "                            else: \n",
        "                                s_vector = vectorizer.fit_transform([s]).toarray()\n",
        "                                x_vector = vectorizer.transform([x]).toarray()\n",
        "\n",
        "                                # Compute similarity between the vectors\n",
        "                                similarity = cosine_similarity(s_vector, x_vector)[0][0]\n",
        "                                if similarity > simG: #max(0.82,sim):\n",
        "                                    similar_k.append(similarity)\n",
        "                                    deiktes.append(k)\n",
        "                                    pairs_k.append((s,x,similarity))\n",
        "\n",
        "                                    if k not in dix:\n",
        "                                        dix[k] = [x]\n",
        "                                    else:\n",
        "                                        dix[k].append(x)\n",
        "                            \n",
        "        similarity_ab.append(similar_k)   \n",
        "        similarity_ab = [lst for lst in similarity_ab if lst != []]\n",
        "        pairs.append(pairs_k)\n",
        "        \n",
        "    \n",
        "    dixDoiAff = {DF['DOI'].iloc[key]: value for key, value in dix.items()} # dictionary {DOI : legalnames} \n",
        "    \n",
        "    #dixDoiPid1 = {key : [dixOpenAIRE[x] for x in value if x in  lnamelist] for key , value in dixDoiAff.items()}\n",
        "    \n",
        "   # dixDoiPid = {key : [dixOpenAIRE[x] for x in value] for key , value in dixDoiAff.items()} # dictionary {DOI : PIDs} \n",
        "    \n",
        "    \n",
        "    \n",
        "## Define the new Dataframe\n",
        "    \n",
        "    doiIdDF = pd.DataFrame()\n",
        "    doiIdDF['DOI'] = list(dixDoiAff.keys())\n",
        "    doiIdDF['Affiliations'] = list(DF['affiliations'].iloc[list(set(deiktes))])\n",
        "\n",
        "    doiIdDF['Unique affiliations'] = list(DF['uniqueAff2'].iloc[list(set(deiktes))])\n",
        "    doiIdDF['light affiliations'] = list(DF['lightAff'].iloc[list(set(deiktes))])\n",
        "\n",
        "    \n",
        "    doiIdDF['# Authors'] = list(DF['# authors'].iloc[list(set(deiktes))])\n",
        "\n",
        "\n",
        "    doiIdDF['# Unique affiliations'] = list(DF['# uniqueAff'].iloc[list(set(deiktes))])\n",
        "\n",
        "    doiIdDF['Candidates for matching'] = list(DF['affilSimpleNew'].iloc[list(set(deiktes))])\n",
        "    doiIdDF['Candidates old'] = list(DF['affilSimple'].iloc[list(set(deiktes))])\n",
        "\n",
        "\n",
        "    doiIdDF['Matched openAIRE names'] = list(dix.values())\n",
        "    doiIdDF['# Matched orgs'] = [len(list(dix.values())[i]) for i in range(len(list(dix.values())))]\n",
        "    \n",
        "\n",
        "    doiIdDF['Similarity score'] = similarity_ab\n",
        "    #perfectSim = [[1 if num >= 1 else 0 for num in inner_list] for inner_list in similarity_ab]\n",
        "\n",
        "    #doiIdDF['Perfect match'] = perfectSim\n",
        "    #perfectSimSum = [sum(x) for x in perfectSim]\n",
        "    #doiIdDF['Perfect sum'] = perfectSimSum\n",
        "    Pairs = [lst for lst in pairs if lst]\n",
        "    doiIdDF['Pairs'] = Pairs\n",
        "    doiIdDF['mult'] = index_multipleMatchings(doiIdDF)[1]\n",
        "    #doiIdDF['Cleaning'] =  list(DF['Cleaning'].iloc[list(set(deiktes))])\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "## Correct the matchings\n",
        "    needCheck = list(set([i for i in range(len(doiIdDF)) for k in list(doiIdDF['mult'].iloc[i].values()) if k>1]))\n",
        "    \n",
        "    #needCheck = [i for i  in range(len(doiIdDF)) if doiIdDF['# Matched orgs'].iloc[i] - max(doiIdDF['# Authors'].iloc[i],doiIdDF['# Unique affiliations'].iloc[i]) >0 or    i in index_multipleMatchings(doiIdDF)[0]]\n",
        "\n",
        "    ready = [i for i in range(len(doiIdDF)) if i not in needCheck]\n",
        "   \n",
        "    best = [ bestSimScore(doiIdDF['light affiliations'].iloc[i], len(doiIdDF['Candidates for matching'].iloc[i]), doiIdDF['Pairs'].iloc[i],doiIdDF['mult'].iloc[i], simU, simG) for i in needCheck]\n",
        "    #best = [ bestSimScore(doiIdDF['light affiliations'].iloc[i], doiIdDF['Matched openAIRE names'].iloc[i], doiIdDF['Pairs'].iloc[i]) for i in needCheck]\n",
        "    best_o = []\n",
        "    best_s = []\n",
        "    \n",
        "    for x in best:\n",
        "        best_o.append([x[i][0]  for i in range(len(x))])\n",
        "        best_s.append([round(x[i][1],2)  for i in range(len(x))])\n",
        "    numMathced = [len(best_s[i]) for i in range(len(needCheck))]\n",
        "    \n",
        "\n",
        "    \n",
        "    dfFinal0 = (doiIdDF.iloc[ready]).copy()\n",
        "    dfFinal0['index'] = ready\n",
        "    \n",
        "    dfFinal1 = (doiIdDF.iloc[needCheck]).copy()\n",
        "    dfFinal1['index'] = needCheck\n",
        "    dfFinal1['Matched openAIRE names'] = best_o\n",
        "    dfFinal1['Similarity score'] = best_s\n",
        "    dfFinal1['# Matched orgs'] = numMathced\n",
        "    \n",
        "    finalDF =  pd.concat([dfFinal0, dfFinal1])\n",
        "    finalDF.set_index('index', inplace=True)\n",
        "    finalDF.sort_values('index', ascending=True, inplace = True)\n",
        "    \n",
        "    ids = [[dixOpenAIRE[x] for x in v] for v in finalDF['Matched openAIRE names']]\n",
        "    numIds = [len(x) for x in ids]\n",
        "\n",
        "    finalDF['IDs'] = ids\n",
        "    finalDF['# IDs'] = numIds\n",
        "    finalDF = finalDF[~(finalDF['# Matched orgs'] == 0)]\n",
        "    \n",
        "    finalDF = finalDF.reset_index(drop=True)\n",
        "    perc = 100*len(finalDF)/m\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    return [perc,finalDF,doiIdDF, needCheck]\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1983,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = Doi_Ids(len(univLabsDF), univLabsDF, dixOpenOrgId2, 0.7,0.82)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1984,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80.078125"
            ]
          },
          "execution_count": 1984,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1985,
      "metadata": {},
      "outputs": [],
      "source": [
        "finaldf = result[1]\n",
        "finalDF = finaldf[[\"Affiliations\", \"Unique affiliations\",'# Authors','# Unique affiliations', '# Matched orgs', 'Matched openAIRE names', 'Similarity score']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1986,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_Z(row):\n",
        "    new_Z = []\n",
        "    for i in range(len(row['IDs'])):\n",
        "        entry = {'openaireId': row['IDs'][i], 'confidence': row['Similarity score'][i]}\n",
        "        new_Z.append(entry)\n",
        "    return new_Z\n",
        "\n",
        "# Update the values in column 'Z' using 'apply'\n",
        "finaldf['affiliations'] = finaldf.apply(update_Z, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1987,
      "metadata": {},
      "outputs": [],
      "source": [
        "finaldf_output = finaldf[['DOI','affiliations']]\n",
        "finaldf_output = finaldf_output.rename(columns={'DOI': 'doi'}).copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1988,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "App saved to ./sample.html"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "app = dp.App(#dp.Page(title=\"Matchings [explained]\", blocks= [dp.Text('DOIs with aff. in Univ/Inst, Laboratories'), dp.DataTable(finalDF.drop(columns =['Candidates old']))]\n",
        "             #), \n",
        "             dp.Page(title=\"Matchings [final]\", \n",
        "                     blocks= [dp.Text('DOIs with aff. in Univ/Inst, Laboratories'), dp.Table(finalDF)]\n",
        "             )\n",
        "             )\n",
        "    \n",
        "\n",
        "\n",
        "   \n",
        "app.save(path=\"sample.html\", open=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1989,
      "metadata": {},
      "outputs": [],
      "source": [
        "match0 = finaldf_output.to_json(orient='records', lines=True)\n",
        "\n",
        "# Save the JSON to a file\n",
        "with open('match0.json', 'w') as f:\n",
        "    f.write(match0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# proxeiro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1990,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['centre provencealpescote dazur',\n",
              " 'institut des materiaux microelectronique et des nanosciences provence',\n",
              " 'universit provence']"
            ]
          },
          "execution_count": 1990,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "findID('provence')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1991,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7071067811865475"
            ]
          },
          "execution_count": 1991,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "\n",
        "s = 'university provence'\n",
        "x = 'universite provence'\n",
        "\n",
        "s_vector = vectorizer.fit_transform([s]).toarray()\n",
        "x_vector = vectorizer.transform([x]).toarray()\n",
        "\n",
        "# Compute similarity between the vectors\n",
        "similarity = cosine_similarity(s_vector, x_vector)[0][0]\n",
        "similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "name": "beginners_kit_zeppelin_notebook"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
