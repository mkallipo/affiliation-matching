{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import pickle\n",
        "\n",
        "#import Levenshtein\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upload json files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = 'sample.json'\n",
        "\n",
        "crossrefDF = pd.read_json(file, orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(crossrefDF)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data preparation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "noAuthors = [i for i in range(len(crossrefDF)) if 'author' not in crossrefDF['items'][i]]\n",
        "\n",
        "Authors = [i for i in range(len(crossrefDF)) if 'author'  in crossrefDF['items'][i]]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rows with authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "crossrefAuth = crossrefDF.iloc[Authors].copy()\n",
        "\n",
        "crossrefAuth.reset_index(inplace= True)\n",
        "crossrefAuth.drop(columns = ['index'], inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>items</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1504/ijil.2023.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;Product management is a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/acsami.2c18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1149/1.1393434',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/acsomega.2c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/jm020002p',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.15278/isms.2022....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;In a 21st century classr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1016/j.jmrt.2022...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1016/0012-365x(9...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>887 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 items\n",
              "0    {'URL': 'http://dx.doi.org/10.1504/ijil.2023.1...\n",
              "1    {'abstract': '<jats:p>Product management is a ...\n",
              "2    {'URL': 'http://dx.doi.org/10.1021/acsami.2c18...\n",
              "3    {'URL': 'http://dx.doi.org/10.1149/1.1393434',...\n",
              "4    {'URL': 'http://dx.doi.org/10.1021/acsomega.2c...\n",
              "..                                                 ...\n",
              "882  {'URL': 'http://dx.doi.org/10.1021/jm020002p',...\n",
              "883  {'URL': 'http://dx.doi.org/10.15278/isms.2022....\n",
              "884  {'abstract': '<jats:p>In a 21st century classr...\n",
              "885  {'URL': 'http://dx.doi.org/10.1016/j.jmrt.2022...\n",
              "886  {'URL': 'http://dx.doi.org/10.1016/0012-365x(9...\n",
              "\n",
              "[887 rows x 1 columns]"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "crossrefAuth"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract 'DOI', authors --- number of authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "crossrefAuth.loc[:, 'DOI'] = crossrefAuth['items'].apply(lambda x: x['DOI'])\n",
        "crossrefAuth.loc[:,'authors'] = crossrefAuth['items'].apply(lambda x: x['author'])\n",
        "\n",
        "numAuthors = [len(crossrefAuth.iloc[i]['authors']) for i in range(len(crossrefAuth))]\n",
        "\n",
        "crossrefAuth.loc[:,'# authors'] = numAuthors"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract 'affiliations' --- number of affiliations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getAff(k):\n",
        "   return [crossrefAuth['authors'][k][j]['affiliation'] for j in range(len(crossrefAuth['authors'][k]))]\n",
        "    \n",
        "Affiliations = [getAff(k) for k in range(len(crossrefAuth))]\n",
        "\n",
        "crossrefAuth.loc[:,'affiliations'] = Affiliations\n",
        "\n",
        "numAffil = [len(Affiliations[i]) for i in range(len(crossrefAuth))]\n",
        "\n",
        "crossrefAuth.loc[:,'# Affil'] = numAffil"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean 'empty' affiliations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "possibleEmptyAff = []\n",
        "\n",
        "for k in range(len(crossrefAuth)):\n",
        "    if len(crossrefAuth['affiliations'][k][0]) == 0:\n",
        "        possibleEmptyAff.append(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "610"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(possibleEmptyAff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "nonEmptyAff = []\n",
        "\n",
        "for k in possibleEmptyAff:\n",
        "    for j in range(len(crossrefAuth['affiliations'].iloc[k])):\n",
        "        if len(crossrefAuth['affiliations'].iloc[k][j]) != 0:\n",
        "            nonEmptyAff.append(k)\n",
        "    \n",
        "FinalEmptyyAff =  [x for x in possibleEmptyAff if x not in nonEmptyAff] \n",
        "FinalNonEmptyAff = [x for x in range(len(crossrefAuth)) if x not in FinalEmptyyAff]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# doiDF: crossrefAuth subdataframe with nonpempty affiliation lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "doiDF = crossrefAuth.iloc[FinalNonEmptyAff].copy()\n",
        "doiDF.reset_index(inplace = True)\n",
        "doiDF.drop(columns = ['index'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>items</th>\n",
              "      <th>DOI</th>\n",
              "      <th>authors</th>\n",
              "      <th># authors</th>\n",
              "      <th>affiliations</th>\n",
              "      <th># Affil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/acsami.2c18...</td>\n",
              "      <td>10.1021/acsami.2c18397</td>\n",
              "      <td>[{'given': 'Guoxian', 'family': 'Zhang', 'sequ...</td>\n",
              "      <td>8</td>\n",
              "      <td>[[{'name': 'Key Laboratory of Special Function...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/acsomega.2c...</td>\n",
              "      <td>10.1021/acsomega.2c04273</td>\n",
              "      <td>[{'given': 'Junlong', 'family': 'Han', 'sequen...</td>\n",
              "      <td>7</td>\n",
              "      <td>[[{'name': 'School of Mechanical Engineering a...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;The article provides a t...</td>\n",
              "      <td>10.54891/2786-7005-2022-1-13</td>\n",
              "      <td>[{'ORCID': 'http://orcid.org/0000-0002-1686-19...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Communal Institution of Higher Edu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.158.8.3587</td>\n",
              "      <td>[{'given': 'S J', 'family': 'Gobin', 'sequence...</td>\n",
              "      <td>4</td>\n",
              "      <td>[[{'name': 'Department of Immunohaematology an...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1061/(asce)0887-...</td>\n",
              "      <td>10.1061/(asce)0887-3828(2002)16:3(98)</td>\n",
              "      <td>[{'given': 'Norbert J.', 'family': 'Delatte', ...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Assistant Professor, Dept. of Civi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;The authors highlight th...</td>\n",
              "      <td>10.4018/978-1-6684-7593-5.ch044</td>\n",
              "      <td>[{'given': 'Renuka', 'family': 'Garg', 'sequen...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Veer Narmad South Gujarat Universi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.159.11.5372</td>\n",
              "      <td>[{'given': 'C J', 'family': 'Howard', 'sequenc...</td>\n",
              "      <td>6</td>\n",
              "      <td>[[{'name': 'The Institute for Animal Health, C...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;: Overcrowding and house...</td>\n",
              "      <td>10.18231/j.jchm.2022.037</td>\n",
              "      <td>[{'given': 'Ravikant Rambhai', 'family': 'Pate...</td>\n",
              "      <td>4</td>\n",
              "      <td>[[], [{'name': 'GMERS Medical College, Valsad,...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.162.12.6967</td>\n",
              "      <td>[{'given': 'Chris A.', 'family': 'Benedict', '...</td>\n",
              "      <td>8</td>\n",
              "      <td>[[{'name': '*Division of Molecular Immunology,...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/jm020002p',...</td>\n",
              "      <td>10.1021/jm020002p</td>\n",
              "      <td>[{'given': 'Rachel A.', 'family': 'Powers', 's...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Department of Molecular Pharmacolo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>278 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 items  \\\n",
              "0    {'URL': 'http://dx.doi.org/10.1021/acsami.2c18...   \n",
              "1    {'URL': 'http://dx.doi.org/10.1021/acsomega.2c...   \n",
              "2    {'abstract': '<jats:p>The article provides a t...   \n",
              "3    {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "4    {'URL': 'http://dx.doi.org/10.1061/(asce)0887-...   \n",
              "..                                                 ...   \n",
              "273  {'abstract': '<jats:p>The authors highlight th...   \n",
              "274  {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "275  {'abstract': '<jats:p>: Overcrowding and house...   \n",
              "276  {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "277  {'URL': 'http://dx.doi.org/10.1021/jm020002p',...   \n",
              "\n",
              "                                       DOI  \\\n",
              "0                   10.1021/acsami.2c18397   \n",
              "1                 10.1021/acsomega.2c04273   \n",
              "2             10.54891/2786-7005-2022-1-13   \n",
              "3              10.4049/jimmunol.158.8.3587   \n",
              "4    10.1061/(asce)0887-3828(2002)16:3(98)   \n",
              "..                                     ...   \n",
              "273        10.4018/978-1-6684-7593-5.ch044   \n",
              "274           10.4049/jimmunol.159.11.5372   \n",
              "275               10.18231/j.jchm.2022.037   \n",
              "276           10.4049/jimmunol.162.12.6967   \n",
              "277                      10.1021/jm020002p   \n",
              "\n",
              "                                               authors  # authors  \\\n",
              "0    [{'given': 'Guoxian', 'family': 'Zhang', 'sequ...          8   \n",
              "1    [{'given': 'Junlong', 'family': 'Han', 'sequen...          7   \n",
              "2    [{'ORCID': 'http://orcid.org/0000-0002-1686-19...          2   \n",
              "3    [{'given': 'S J', 'family': 'Gobin', 'sequence...          4   \n",
              "4    [{'given': 'Norbert J.', 'family': 'Delatte', ...          2   \n",
              "..                                                 ...        ...   \n",
              "273  [{'given': 'Renuka', 'family': 'Garg', 'sequen...          2   \n",
              "274  [{'given': 'C J', 'family': 'Howard', 'sequenc...          6   \n",
              "275  [{'given': 'Ravikant Rambhai', 'family': 'Pate...          4   \n",
              "276  [{'given': 'Chris A.', 'family': 'Benedict', '...          8   \n",
              "277  [{'given': 'Rachel A.', 'family': 'Powers', 's...          2   \n",
              "\n",
              "                                          affiliations  # Affil  \n",
              "0    [[{'name': 'Key Laboratory of Special Function...        8  \n",
              "1    [[{'name': 'School of Mechanical Engineering a...        7  \n",
              "2    [[{'name': 'Communal Institution of Higher Edu...        2  \n",
              "3    [[{'name': 'Department of Immunohaematology an...        4  \n",
              "4    [[{'name': 'Assistant Professor, Dept. of Civi...        2  \n",
              "..                                                 ...      ...  \n",
              "273  [[{'name': 'Veer Narmad South Gujarat Universi...        2  \n",
              "274  [[{'name': 'The Institute for Animal Health, C...        6  \n",
              "275  [[], [{'name': 'GMERS Medical College, Valsad,...        4  \n",
              "276  [[{'name': '*Division of Molecular Immunology,...        8  \n",
              "277  [[{'name': 'Department of Molecular Pharmacolo...        2  \n",
              "\n",
              "[278 rows x 6 columns]"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doiDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>items</th>\n",
              "      <th>DOI</th>\n",
              "      <th>authors</th>\n",
              "      <th># authors</th>\n",
              "      <th>affiliations</th>\n",
              "      <th># Affil</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/acsami.2c18...</td>\n",
              "      <td>10.1021/acsami.2c18397</td>\n",
              "      <td>[{'given': 'Guoxian', 'family': 'Zhang', 'sequ...</td>\n",
              "      <td>8</td>\n",
              "      <td>[[{'name': 'Key Laboratory of Special Function...</td>\n",
              "      <td>8</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1021/acsomega.2c...</td>\n",
              "      <td>10.1021/acsomega.2c04273</td>\n",
              "      <td>[{'given': 'Junlong', 'family': 'Han', 'sequen...</td>\n",
              "      <td>7</td>\n",
              "      <td>[[{'name': 'School of Mechanical Engineering a...</td>\n",
              "      <td>7</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;The article provides a t...</td>\n",
              "      <td>10.54891/2786-7005-2022-1-13</td>\n",
              "      <td>[{'ORCID': 'http://orcid.org/0000-0002-1686-19...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Communal Institution of Higher Edu...</td>\n",
              "      <td>2</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.158.8.3587</td>\n",
              "      <td>[{'given': 'S J', 'family': 'Gobin', 'sequence...</td>\n",
              "      <td>4</td>\n",
              "      <td>[[{'name': 'Department of Immunohaematology an...</td>\n",
              "      <td>4</td>\n",
              "      <td>1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1061/(asce)0887-...</td>\n",
              "      <td>10.1061/(asce)0887-3828(2002)16:3(98)</td>\n",
              "      <td>[{'given': 'Norbert J.', 'family': 'Delatte', ...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Assistant Professor, Dept. of Civi...</td>\n",
              "      <td>2</td>\n",
              "      <td>2002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.15280/jlm.2022.1...</td>\n",
              "      <td>10.15280/jlm.2022.12.3.138</td>\n",
              "      <td>[{'given': 'Abhishek', 'family': 'Sharma', 'se...</td>\n",
              "      <td>3</td>\n",
              "      <td>[[{'name': 'Department of Paediatric and Neona...</td>\n",
              "      <td>3</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.25253/99.2022244...</td>\n",
              "      <td>10.25253/99.2022244.11</td>\n",
              "      <td>[{'ORCID': 'http://orcid.org/0000-0002-0585-54...</td>\n",
              "      <td>1</td>\n",
              "      <td>[[{'name': 'Aksaray University, Türkiye'}]]</td>\n",
              "      <td>1</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{'abstract': '&lt;jats:title&gt;Abstract&lt;/jats:title...</td>\n",
              "      <td>10.4049/jimmunol.159.11.5535</td>\n",
              "      <td>[{'given': 'F H', 'family': 'Amante', 'sequenc...</td>\n",
              "      <td>4</td>\n",
              "      <td>[[{'name': 'The Cooperative Research Center fo...</td>\n",
              "      <td>4</td>\n",
              "      <td>1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'URL': 'http://dx.doi.org/10.1080/23322039.20...</td>\n",
              "      <td>10.1080/23322039.2022.2161774</td>\n",
              "      <td>[{'ORCID': 'http://orcid.org/0000-0002-9452-09...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[{'name': 'Pan African University Institute o...</td>\n",
              "      <td>2</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{'abstract': '&lt;jats:p&gt;Cryptocurrencies show so...</td>\n",
              "      <td>10.22495/rgcv12i4p5</td>\n",
              "      <td>[{'ORCID': 'http://orcid.org/0000-0001-9173-56...</td>\n",
              "      <td>3</td>\n",
              "      <td>[[{'name': 'Masaryk University'}], [{'name': '...</td>\n",
              "      <td>3</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               items  \\\n",
              "0  {'URL': 'http://dx.doi.org/10.1021/acsami.2c18...   \n",
              "1  {'URL': 'http://dx.doi.org/10.1021/acsomega.2c...   \n",
              "2  {'abstract': '<jats:p>The article provides a t...   \n",
              "3  {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "4  {'URL': 'http://dx.doi.org/10.1061/(asce)0887-...   \n",
              "5  {'URL': 'http://dx.doi.org/10.15280/jlm.2022.1...   \n",
              "6  {'URL': 'http://dx.doi.org/10.25253/99.2022244...   \n",
              "7  {'abstract': '<jats:title>Abstract</jats:title...   \n",
              "8  {'URL': 'http://dx.doi.org/10.1080/23322039.20...   \n",
              "9  {'abstract': '<jats:p>Cryptocurrencies show so...   \n",
              "\n",
              "                                     DOI  \\\n",
              "0                 10.1021/acsami.2c18397   \n",
              "1               10.1021/acsomega.2c04273   \n",
              "2           10.54891/2786-7005-2022-1-13   \n",
              "3            10.4049/jimmunol.158.8.3587   \n",
              "4  10.1061/(asce)0887-3828(2002)16:3(98)   \n",
              "5             10.15280/jlm.2022.12.3.138   \n",
              "6                 10.25253/99.2022244.11   \n",
              "7           10.4049/jimmunol.159.11.5535   \n",
              "8          10.1080/23322039.2022.2161774   \n",
              "9                    10.22495/rgcv12i4p5   \n",
              "\n",
              "                                             authors  # authors  \\\n",
              "0  [{'given': 'Guoxian', 'family': 'Zhang', 'sequ...          8   \n",
              "1  [{'given': 'Junlong', 'family': 'Han', 'sequen...          7   \n",
              "2  [{'ORCID': 'http://orcid.org/0000-0002-1686-19...          2   \n",
              "3  [{'given': 'S J', 'family': 'Gobin', 'sequence...          4   \n",
              "4  [{'given': 'Norbert J.', 'family': 'Delatte', ...          2   \n",
              "5  [{'given': 'Abhishek', 'family': 'Sharma', 'se...          3   \n",
              "6  [{'ORCID': 'http://orcid.org/0000-0002-0585-54...          1   \n",
              "7  [{'given': 'F H', 'family': 'Amante', 'sequenc...          4   \n",
              "8  [{'ORCID': 'http://orcid.org/0000-0002-9452-09...          2   \n",
              "9  [{'ORCID': 'http://orcid.org/0000-0001-9173-56...          3   \n",
              "\n",
              "                                        affiliations  # Affil  year  \n",
              "0  [[{'name': 'Key Laboratory of Special Function...        8  2022  \n",
              "1  [[{'name': 'School of Mechanical Engineering a...        7  2022  \n",
              "2  [[{'name': 'Communal Institution of Higher Edu...        2  2022  \n",
              "3  [[{'name': 'Department of Immunohaematology an...        4  1997  \n",
              "4  [[{'name': 'Assistant Professor, Dept. of Civi...        2  2002  \n",
              "5  [[{'name': 'Department of Paediatric and Neona...        3  2022  \n",
              "6        [[{'name': 'Aksaray University, Türkiye'}]]        1  2022  \n",
              "7  [[{'name': 'The Cooperative Research Center fo...        4  1997  \n",
              "8  [[{'name': 'Pan African University Institute o...        2  2022  \n",
              "9  [[{'name': 'Masaryk University'}], [{'name': '...        3  2022  "
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "year = [(doiDF['items'].iloc[i]['issued']['date-parts'][0][0]) for i in range(len(doiDF))]\n",
        "\n",
        "doiDF['year'] = year\n",
        "\n",
        "        \n",
        "        \n",
        "doiDF.head(10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (still some cleaning: cases with empty brackets [{}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in range(len(doiDF)):\n",
        "    if len(doiDF['affiliations'][k][0]) != 0 and doiDF['affiliations'][k][0][0] == {}:\n",
        "        print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "emptyBrackets = [k for k in range(len(doiDF)) if len(doiDF['affiliations'][k][0]) != 0 and doiDF['affiliations'][k][0][0] == {}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>items</th>\n",
              "      <th>DOI</th>\n",
              "      <th>authors</th>\n",
              "      <th># authors</th>\n",
              "      <th>affiliations</th>\n",
              "      <th># Affil</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [items, DOI, authors, # authors, affiliations, # Affil, year]\n",
              "Index: []"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doiDF.iloc[emptyBrackets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "doiDF.drop(emptyBrackets, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "doiDF.reset_index(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "doiDF.drop(columns = ['index'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "278"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(doiDF)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clean affiliations "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## is_contained(a,b) map : returns true when a is a substring of b "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_contained(s, w):\n",
        "    words = s.split()  # Split the string 's' into a list of words\n",
        "    for word in words:\n",
        "        if word not in w:  # If a word from 's' is not found in 'w'\n",
        "            return False  # Return False immediately\n",
        "    return True  # If all words from 's' are found in 'w', return True"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. \"Unique\" affiliations --- number of unique affiliations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error indices: []\n"
          ]
        }
      ],
      "source": [
        "uniqueAff = []\n",
        "error_indices =[] # New list to store error indices\n",
        "for i in range(len(doiDF)):\n",
        "    try:\n",
        "        uniqueAff.append(list(set([x[0] for x in [list(d.values()) for d in [item for sublist in doiDF['affiliations'].iloc[i] for item in sublist if sublist !=[{}] and item !={}]]])))\n",
        "    except TypeError:\n",
        "        print(\"Error occurred for i =\", i)\n",
        "        error_indices.append(i)  # Save the index where the error occurred\n",
        "    #except IndexError:\n",
        "     #   print(\"IndexError occurred for i =\", i)\n",
        "      #  error_indices.append(i)  # Save the index where the IndexError occurred\n",
        "\n",
        "\n",
        "# Print the error indices\n",
        "print(\"Error indices:\", error_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "doiDF.drop(error_indices, inplace = True)\n",
        "doiDF.reset_index(inplace = True)\n",
        "doiDF.drop(columns = ['index'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "doiDF.loc[:,'uniqueAff'] = uniqueAff\n",
        "\n",
        "numUniqueAff = [len(doiDF['uniqueAff'].iloc[i]) for i in range(len(doiDF))]\n",
        "\n",
        "doiDF.loc[:,'# uniqueAff'] = numUniqueAff"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Remove stop words "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "doiDF.loc[:,'uniqueAff1'] = doiDF['uniqueAff'].apply(lambda x: [s.lower() for s in x])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "stopWords = ['from', 'the', 'of', 'at', 'de','for','et','für','des', 'in','as','a','and']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_stop_words(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stopWords]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "\n",
        "# apply the function to the column  doiDF['uniqueAff'] to create column doiDF.loc[:,'uniqueAff1']\n",
        "\n",
        "doiDF.loc[:,'uniqueAff1'] = doiDF['uniqueAff'].apply(lambda x: [remove_stop_words(s) for s in x])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Remove parenthesis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_parentheses(text):\n",
        "   return re.sub(r'\\([^()]*\\)', '', text)\n",
        "\n",
        "# apply the function to each list element of column doiDF['uniqueAff1'] to remove substrings inside parentheses\n",
        "\n",
        "doiDF.loc[:,'uniqueAff1'] = doiDF['uniqueAff1'].apply(lambda x: [remove_parentheses(s) for s in x])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Remove @#$%characters and umlauts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "def replace_umlauts(text):\n",
        "    normalized_text = unicodedata.normalize('NFKD', text)\n",
        "    replaced_text = ''.join(c for c in normalized_text if not unicodedata.combining(c))\n",
        "    return replaced_text\n",
        "\n",
        "affNoSymbols = []\n",
        "\n",
        "for i in range(len(list(doiDF['uniqueAff1']))):\n",
        "    L = list(doiDF['uniqueAff1'])[i]\n",
        "    for j in range(len(L)):\n",
        "        L[j] = re.sub(r'[^\\w\\s,Α-Ωα-ωぁ-んァ-ン一-龯，]', '', L[j])\n",
        "        L[j] = L[j].replace(\"  \", \" \")\n",
        "        L[j] = replace_umlauts(L[j])\n",
        "        \n",
        "    affNoSymbols.append(L)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [],
      "source": [
        "affNoSymbols = [[item for item in inner_list if item != \"inc\"] for inner_list in affNoSymbols]\n",
        "\n",
        "doiDF['uniqueAff1'] = affNoSymbols"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Check 'sub'-affiliations (affiliations that are contained in other affiliations of the same DOI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [],
      "source": [
        "newAff0 = []\n",
        "\n",
        "for k in range(len(doiDF)):\n",
        "    \n",
        "    L2 = []\n",
        "    for s1 in doiDF['uniqueAff1'].iloc[k]:\n",
        "        is_substring = False\n",
        "        for s2 in doiDF['uniqueAff1'].iloc[k]:\n",
        "            if s1 != s2 and s1 in s2:\n",
        "                is_substring = True\n",
        "                break\n",
        "        if not is_substring:\n",
        "            L2.append(s1)\n",
        "    newAff0.append(L2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [],
      "source": [
        "newAffList = [list(set(newAff0[k])) for k in range(len(newAff0))]\n",
        "doiDF['Unique affiliations'] = newAffList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [],
      "source": [
        "allAffsList = []\n",
        "\n",
        "for doi in newAffList:\n",
        "    for aff in doi:\n",
        "        if aff not in allAffsList:\n",
        "            allAffsList.append(aff)\n",
        "        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Split strings where ',' or ';' appears    | Apply .lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [],
      "source": [
        "def substringsDict(string):\n",
        "    split_strings = [re.sub(r'^[\\s.]+|[\\s.]+$', '', s.strip()) for s in re.split(r'[,;]', string)]\n",
        "    dict_string = {}\n",
        "    index = 0\n",
        "\n",
        "    for value in split_strings:\n",
        "        if value:\n",
        "            modified_value = re.sub(r'\\buniversit\\w*', 'universit', value, flags=re.IGNORECASE)\n",
        "            dict_string[index] = modified_value.lower()\n",
        "            index += 1\n",
        "\n",
        "    return dict_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "newAffkomma = []\n",
        "\n",
        "for aff in allAffsList:\n",
        "    newAffkomma.append(substringsDict(aff))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [],
      "source": [
        "for dict in newAffkomma:\n",
        "    \n",
        "    if len(dict)>1:\n",
        "        for i in range(len(dict)-1):\n",
        "            if is_contained('progr', dict[i]) and is_contained('dep', dict[i+1]):\n",
        "                del dict[i]\n",
        "            elif (is_contained('assistant', dict[i]) or is_contained('researcher', dict[i]) or is_contained('phd', dict[i]) or is_contained('student', dict[i]) or is_contained('section', dict[i]) or is_contained('prof', dict[i]) or is_contained('director', dict[i])) and (not is_contained('school', dict[i+1]) or is_contained('univ', dict[i+1]) or is_contained('inst', dict[i+1]) or is_contained('lab', dict[i+1]) or is_contained('fac', dict[i+1])):\n",
        "                del dict[i]\n",
        "            elif (is_contained('engineer', dict[i]) or is_contained('progr', dict[i]) or is_contained('unit', dict[i]) or is_contained('lab', dict[i]) or is_contained('dep', dict[i]) or is_contained('inst', dict[i]) or is_contained('hosp', dict[i]) or is_contained('school', dict[i]) or is_contained('fac', dict[i])) and is_contained('univ', dict[i+1]):\n",
        "                del dict[i]\n",
        "            elif is_contained('lab', dict[i]) and (is_contained('college', dict[i+1]) or is_contained('inst', dict[i+1]) or is_contained('dep', dict[i+1]) or is_contained('school', dict[i+1])):\n",
        "                del dict[i]\n",
        "            elif is_contained('dep', dict[i]) and (is_contained('tech', dict[i+1]) or is_contained('college', dict[i+1]) or is_contained('inst', dict[i+1]) or  is_contained('hosp', dict[i+1]) or  is_contained('school', dict[i+1]) or  is_contained('fac', dict[i+1])):\n",
        "                del dict[i]\n",
        "            elif is_contained('inst',dict[i]) and (is_contained('dep', dict[i+1]) or is_contained('acad', dict[i+1]) or is_contained('hosp', dict[i+1]) or is_contained('fac', dict[i+1]) or is_contained('cent', dict[i+1]) or is_contained('div', dict[i+1])):\n",
        "                del dict[i]\n",
        "            elif is_contained('hosp',dict[i]) and is_contained('school', dict[i+1]):\n",
        "                del dict[i]\n",
        "         #   elif is_contained('hos',dict[i]) and (is_contained('cen', dict[i+1]):\n",
        "         #       del dict[i+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "lightAff = []\n",
        "for dict in newAffkomma:\n",
        "    lightAff.append(', '.join(list(dict.values())))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [],
      "source": [
        "removeList = ['university','research institute','laboratory' , 'universit','gmbh', 'inc', 'university of', 'research center', \n",
        "'university college','national institute of', 'school of medicine', \"university school\", 'graduate school of', 'graduate school of engineering', \n",
        "'institute of tropical medicine', 'institute of virology', 'faculty of medicine','laboratory', 'university park', 'institute of science','Polytechnic University']\n",
        "\n",
        "city_names = [\"Aberdeen\", \"Abilene\", \"Akron\", \"Albany\", \"Albuquerque\", \"Alexandria\", \"Allentown\", \"Amarillo\", \"Anaheim\", \"Anchorage\", \"Ann Arbor\", \"Antioch\", \"Apple Valley\", \"Appleton\", \"Arlington\", \"Arvada\", \"Asheville\", \"Athens\", \"Atlanta\", \"Atlantic City\", \"Augusta\", \"Aurora\", \"Austin\", \"Bakersfield\", \"Baltimore\", \"Barnstable\", \"Baton Rouge\", \"Beaumont\", \"Bel Air\", \"Bellevue\", \"Berkeley\", \"Bethlehem\", \"Billings\", \"Birmingham\", \"Bloomington\", \"Boise\", \"Boise City\", \"Bonita Springs\", \"Boston\", \"Boulder\", \"Bradenton\", \"Bremerton\", \"Bridgeport\", \"Brighton\", \"Brownsville\", \"Bryan\", \"Buffalo\", \"Burbank\", \"Burlington\", \"Cambridge\", \"Canton\", \"Cape Coral\", \"Carrollton\", \"Cary\", \"Cathedral City\", \"Cedar Rapids\", \"Champaign\", \"Chandler\", \"Charleston\", \"Charlotte\", \"Chattanooga\", \"Chesapeake\", \"Chicago\", \"Chula Vista\", \"Cincinnati\", \"Clarke County\", \"Clarksville\", \"Clearwater\", \"Cleveland\", \"College Station\", \"Colorado Springs\", \"Columbia\", \"Columbus\", \"Concord\", \"Coral Springs\", \"Corona\", \"Corpus Christi\", \"Costa Mesa\", \"Dallas\", \"Daly City\", \"Danbury\", \"Davenport\", \"Davidson County\", \"Dayton\", \"Daytona Beach\", \"Deltona\", \"Denton\", \"Denver\", \"Des Moines\", \"Detroit\", \"Downey\", \"Duluth\", \"Durham\", \"El Monte\", \"El Paso\", \"Elizabeth\", \"Elk Grove\", \"Elkhart\", \"Erie\", \"Escondido\", \"Eugene\", \"Evansville\", \"Fairfield\", \"Fargo\", \"Fayetteville\", \"Fitchburg\", \"Flint\", \"Fontana\", \"Fort Collins\", \"Fort Lauderdale\", \"Fort Smith\", \"Fort Walton Beach\", \"Fort Wayne\", \"Fort Worth\", \"Frederick\", \"Fremont\", \"Fresno\", \"Fullerton\", \"Gainesville\", \"Garden Grove\", \"Garland\", \"Gastonia\", \"Gilbert\", \"Glendale\", \"Grand Prairie\", \"Grand Rapids\", \"Grayslake\", \"Green Bay\", \"GreenBay\", \"Greensboro\", \"Greenville\", \"Gulfport-Biloxi\", \"Hagerstown\", \"Hampton\", \"Harlingen\", \"Harrisburg\", \"Hartford\", \"Havre de Grace\", \"Hayward\", \"Hemet\", \"Henderson\", \"Hesperia\", \"Hialeah\", \"Hickory\", \"High Point\", \"Hollywood\", \"Honolulu\", \"Houma\", \"Houston\", \"Howell\", \"Huntington\", \"Huntington Beach\", \"Huntsville\", \"Independence\", \"Indianapolis\", \"Inglewood\", \"Irvine\", \"Irving\", \"Jackson\", \"Jacksonville\", \"Jefferson\", \"Jersey City\", \"Johnson City\", \"Joliet\", \"Kailua\", \"Kalamazoo\", \"Kaneohe\", \"Kansas City\", \"Kennewick\", \"Kenosha\", \"Killeen\", \"Kissimmee\", \"Knoxville\", \"Lacey\", \"Lafayette\", \"Lake Charles\", \"Lakeland\", \"Lakewood\", \"Lancaster\", \"Lansing\", \"Laredo\", \"Las Cruces\", \"Las Vegas\", \"Layton\", \"Leominster\", \"Lewisville\", \"Lexington\", \"Lincoln\", \"Little Rock\", \"Long Beach\", \"Lorain\", \"Los Angeles\", \"Louisville\", \"Lowell\", \"Lubbock\", \"Macon\", \"Madison\", \"Manchester\", \"Marina\", \"Marysville\", \"McAllen\", \"McHenry\", \"Medford\", \"Melbourne\", \"Memphis\", \"Merced\", \"Mesa\", \"Mesquite\", \"Miami\", \"Milwaukee\", \"Minneapolis\", \"Miramar\", \"Mission Viejo\", \"Mobile\", \"Modesto\", \"Monroe\", \"Monterey\", \"Montgomery\", \"Moreno Valley\", \"Murfreesboro\", \"Murrieta\", \"Muskegon\", \"Myrtle Beach\", \"Naperville\", \"Naples\", \"Nashua\", \"Nashville\", \"New Bedford\", \"New Haven\", \"New London\", \"New Orleans\", \"New York\", \"New York City\", \"Newark\", \"Newburgh\", \"Newport News\", \"Norfolk\", \"Normal\", \"Norman\", \"North Charleston\", \"North Las Vegas\", \"North Port\", \"Norwalk\", \"Norwich\", \"Oakland\", \"Ocala\", \"Oceanside\", \"Odessa\", \"Ogden\", \"Oklahoma City\", \"Olathe\", \"Olympia\", \"Omaha\", \"Ontario\", \"Orange\", \"Orem\", \"Orlando\", \"Overland Park\", \"Oxnard\", \"Palm Bay\", \"Palm Springs\", \"Palmdale\", \"Panama City\", \"Pasadena\", \"Paterson\", \"Pembroke Pines\", \"Pensacola\", \"Peoria\", \"Philadelphia\", \"Phoenix\", \"Pittsburgh\", \"Plano\", \"Pomona\", \"Pompano Beach\", \"Port Arthur\", \"Port Orange\", \"Port Saint Lucie\", \"Port St. Lucie\", \"Portland\", \"Portsmouth\", \"Poughkeepsie\", \"Providence\", \"Provo\", \"Pueblo\", \"Punta Gorda\", \"Racine\", \"Raleigh\", \"Rancho Cucamonga\", \"Reading\", \"Redding\", \"Reno\", \"Richland\", \"Richmond\", \"Richmond County\", \"Riverside\", \"Roanoke\", \"Rochester\", \"Rockford\", \"Roseville\", \"Round Lake Beach\", \"Sacramento\", \"Saginaw\", \"Saint Louis\", \"Saint Paul\", \"Saint Petersburg\", \"Salem\", \"Salinas\", \"Salt Lake City\", \"San Antonio\", \"San Bernardino\", \"San Buenaventura\", \"San Diego\", \"San Francisco\", \"San Jose\", \"Santa Ana\", \"Santa Barbara\", \"Santa Clara\", \"Santa Clarita\", \"Santa Cruz\", \"Santa Maria\", \"Santa Rosa\", \"Sarasota\", \"Savannah\", \"Scottsdale\", \"Scranton\", \"Seaside\", \"Seattle\", \"Sebastian\", \"Shreveport\", \"Simi Valley\", \"Sioux City\", \"Sioux Falls\", \"South Bend\", \"South Lyon\", \"Spartanburg\", \"Spokane\", \"Springdale\", \"Springfield\", \"St. Louis\", \"St. Paul\", \"St. Petersburg\", \"Stamford\", \"Sterling Heights\", \"Stockton\", \"Sunnyvale\", \"Syracuse\", \"Tacoma\", \"Tallahassee\", \"Tampa\", \"Temecula\", \"Tempe\", \"Thornton\", \"Thousand Oaks\", \"Toledo\", \"Topeka\", \"Torrance\", \"Trenton\", \"Tucson\", \"Tulsa\", \"Tuscaloosa\", \"Tyler\", \"Utica\", \"Vallejo\", \"Vancouver\", \"Vero Beach\", \"Victorville\", \"Virginia Beach\", \"Visalia\", \"Waco\", \"Warren\", \"Washington\", \"Waterbury\", \"Waterloo\", \"West Covina\", \"West Valley City\", \"Westminster\", \"Wichita\", \"Wilmington\", \"Winston\", \"Winter Haven\", \"Worcester\", \"Yakima\", \"Yonkers\", \"York\", \"Youngstown\"]\n",
        "\n",
        "city_names = [x.lower() for x in city_names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [],
      "source": [
        "for dict in newAffkomma:\n",
        "    for i in list(dict.keys()):\n",
        "\n",
        "        if dict[i] in city_names+removeList:\n",
        "            del dict[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [],
      "source": [
        "affDF = pd.DataFrame()\n",
        "affDF['Original Affiliations'] = allAffsList\n",
        "affDF['Light Affiliations'] = lightAff\n",
        "affDF['Keywords'] =  [list(d.values()) for d in newAffkomma]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Labels based on legalnames of openAIRE's organizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [],
      "source": [
        "uniList = ['institu', 'istitut', 'univ', 'coll', 'center','polytechnic', 'centre' , 'cnrs', 'faculty','school' , 'academy' , 'akadem','école', 'hochschule' , 'ecole', 'tech', 'observ']\n",
        "\n",
        "labList = ['lab']\n",
        "\n",
        "hosplList = ['hospital' ,'clinic', 'hôpital', 'klinik','oncol','medical']\n",
        "\n",
        "gmbhList = ['gmbh', 'company' , 'industr', 'etaireia' , 'corporation', 'inc']\n",
        "\n",
        "musList =  ['museum', 'library']\n",
        "\n",
        "foundList =  ['foundation' , 'association','organization' ,'society', 'group' ]\n",
        "\n",
        "deptList = ['district' , 'federation'  , 'government' , 'municipal' , 'county','council', 'agency']\n",
        "# miistry -> out\n",
        "\n",
        "unknownList = ['unknown']\n",
        "\n",
        "#######   Dictionaries ##########\n",
        "\n",
        "uniDict = {k: 'Univ/Inst' for k in uniList}   \n",
        "\n",
        "labDict = {k: 'Laboratory' for k in labList} \n",
        "\n",
        "hosplDict = {k: 'Hospital' for k in hosplList}   \n",
        "\n",
        "gmbhDict = {k: 'Company' for k in gmbhList}   \n",
        "\n",
        "musDict = {k: 'Museum' for k in musList}   \n",
        "\n",
        "#schoolDict = {k: 'School' for k in schoolList}   \n",
        "\n",
        "foundDict = {k: 'Foundation' for k in foundList}   \n",
        "\n",
        "deptDict = {k: 'Government' for k in deptList}   \n",
        "\n",
        "unknownDict =  {k: 'Unknown' for k in unknownList}   \n",
        "\n",
        "categDictsList = [uniDict, labDict, hosplDict, gmbhDict, musDict, #schoolDict, \n",
        "                  foundDict, deptDict, unknownDict]\n",
        "\n",
        "################# Final Dictionary #####################\n",
        "\n",
        "categDicts = {}\n",
        "i = 0\n",
        "while i in range(len(categDictsList)):\n",
        "    categDicts.update(categDictsList[i])\n",
        "    i = i+1\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## affiliationsDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [],
      "source": [
        "affiliationsDict = {}\n",
        "\n",
        "for i in range(len(affDF)):\n",
        "    affiliationsDict[i] = affDF['Keywords'].iloc[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_new = {}\n",
        "\n",
        "# iterate over the keys of affiliationsDict\n",
        "for k in range(len(affiliationsDict)):\n",
        "    # get the list associated with the current key in affiliationsDict\n",
        "    L = affiliationsDict.get(k, [])\n",
        "    mapped_listx = [[s, v] for s in L for k2, v in categDicts.items() if k2 in s]\n",
        "    \n",
        "\n",
        "    # add the mapped list to the new dictionary d_new\n",
        "    d_new[k] = mapped_listx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "affDF['Dictionary'] = list(d_new.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "notInList = [i for i in range(len(affDF)) if affDF['Dictionary'].iloc[i] == []]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "241"
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(doiDF)  - len(notInList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(notInList)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# doiDF1 ['DOI', 'affiliations', 'Dictionary', 'uniqueAff2','# authors','# uniqueAff']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## New column: category based on the labels "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [],
      "source": [
        "category = [', '.join(list(set([x[1] for x in affDF['Dictionary'].iloc[i]]))) for i in range(len(affDF))]\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [],
      "source": [
        "affDF.loc[:, 'Category'] = category\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### new label: rest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(affDF)):\n",
        "    if affDF['Category'].iloc[i] == '':\n",
        "        affDF.iloc[i, affDF.columns.get_loc('Category')] = 'Rest'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "affiliationsSimple = [\n",
        "    list(set([x[0] for x in affDF['Dictionary'].iloc[i]]))\n",
        "    for i in range(len(affDF))\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [],
      "source": [
        "affDF['Keywords'] = affiliationsSimple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original Affiliations</th>\n",
              "      <th>Light Affiliations</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Dictionary</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Key Laboratory Special Functional Smart Polyme...</td>\n",
              "      <td>northwestern polytechnical universit, xian, sh...</td>\n",
              "      <td>[northwestern polytechnical universit]</td>\n",
              "      <td>[[northwestern polytechnical universit, Univ/I...</td>\n",
              "      <td>Univ/Inst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>College Bioresources Chemical Materials Engine...</td>\n",
              "      <td>college bioresources chemical materials engine...</td>\n",
              "      <td>[college bioresources chemical materials engin...</td>\n",
              "      <td>[[college bioresources chemical materials engi...</td>\n",
              "      <td>Univ/Inst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Shenzhen Polytechnic, Shenzhen518055, China</td>\n",
              "      <td>shenzhen polytechnic, shenzhen518055, china</td>\n",
              "      <td>[shenzhen polytechnic]</td>\n",
              "      <td>[[shenzhen polytechnic, Univ/Inst], [shenzhen ...</td>\n",
              "      <td>Univ/Inst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>School Mechanical Engineering Automation, Harb...</td>\n",
              "      <td>school mechanical engineering automation, harb...</td>\n",
              "      <td>[school mechanical engineering automation, har...</td>\n",
              "      <td>[[school mechanical engineering automation, Un...</td>\n",
              "      <td>Univ/Inst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>College Physics Optoelectronic Engineering, Sh...</td>\n",
              "      <td>shenzhen universit, shenzhen518055, china</td>\n",
              "      <td>[shenzhen universit]</td>\n",
              "      <td>[[shenzhen universit, Univ/Inst]]</td>\n",
              "      <td>Univ/Inst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Communal Institution Higher Education Dnipro A...</td>\n",
              "      <td>communal institution higher education dnipro a...</td>\n",
              "      <td>[communal institution higher education dnipro ...</td>\n",
              "      <td>[[communal institution higher education dnipro...</td>\n",
              "      <td>Univ/Inst, Government</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Department Immunohaematology Blood Bank, Leide...</td>\n",
              "      <td>leiden universit hospital, the netherlands</td>\n",
              "      <td>[leiden universit hospital]</td>\n",
              "      <td>[[leiden universit hospital, Univ/Inst], [leid...</td>\n",
              "      <td>Univ/Inst, Hospital</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Associate Professor, Dept Civil Engineering, 1...</td>\n",
              "      <td>dept civil engineering, 1200 larimer st, univ ...</td>\n",
              "      <td>[univ colorado denver]</td>\n",
              "      <td>[[univ colorado denver, Univ/Inst]]</td>\n",
              "      <td>Univ/Inst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Assistant Professor, Dept Civil Environmental ...</td>\n",
              "      <td>dept civil environmental engineering, 1075 13t...</td>\n",
              "      <td>[univ alabama birmingham]</td>\n",
              "      <td>[[univ alabama birmingham, Univ/Inst], [univ a...</td>\n",
              "      <td>Univ/Inst, Laboratory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Department Musculoskeletal Physiotherapy, Maha...</td>\n",
              "      <td>maharishi markandeshwar institute physiotherap...</td>\n",
              "      <td>[maharishi markandeshwar institute physiothera...</td>\n",
              "      <td>[[maharishi markandeshwar institute physiother...</td>\n",
              "      <td>Univ/Inst</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Original Affiliations  \\\n",
              "0  Key Laboratory Special Functional Smart Polyme...   \n",
              "1  College Bioresources Chemical Materials Engine...   \n",
              "2        Shenzhen Polytechnic, Shenzhen518055, China   \n",
              "3  School Mechanical Engineering Automation, Harb...   \n",
              "4  College Physics Optoelectronic Engineering, Sh...   \n",
              "5  Communal Institution Higher Education Dnipro A...   \n",
              "6  Department Immunohaematology Blood Bank, Leide...   \n",
              "7  Associate Professor, Dept Civil Engineering, 1...   \n",
              "8  Assistant Professor, Dept Civil Environmental ...   \n",
              "9  Department Musculoskeletal Physiotherapy, Maha...   \n",
              "\n",
              "                                  Light Affiliations  \\\n",
              "0  northwestern polytechnical universit, xian, sh...   \n",
              "1  college bioresources chemical materials engine...   \n",
              "2        shenzhen polytechnic, shenzhen518055, china   \n",
              "3  school mechanical engineering automation, harb...   \n",
              "4          shenzhen universit, shenzhen518055, china   \n",
              "5  communal institution higher education dnipro a...   \n",
              "6         leiden universit hospital, the netherlands   \n",
              "7  dept civil engineering, 1200 larimer st, univ ...   \n",
              "8  dept civil environmental engineering, 1075 13t...   \n",
              "9  maharishi markandeshwar institute physiotherap...   \n",
              "\n",
              "                                            Keywords  \\\n",
              "0             [northwestern polytechnical universit]   \n",
              "1  [college bioresources chemical materials engin...   \n",
              "2                             [shenzhen polytechnic]   \n",
              "3  [school mechanical engineering automation, har...   \n",
              "4                               [shenzhen universit]   \n",
              "5  [communal institution higher education dnipro ...   \n",
              "6                        [leiden universit hospital]   \n",
              "7                             [univ colorado denver]   \n",
              "8                          [univ alabama birmingham]   \n",
              "9  [maharishi markandeshwar institute physiothera...   \n",
              "\n",
              "                                          Dictionary               Category  \n",
              "0  [[northwestern polytechnical universit, Univ/I...              Univ/Inst  \n",
              "1  [[college bioresources chemical materials engi...              Univ/Inst  \n",
              "2  [[shenzhen polytechnic, Univ/Inst], [shenzhen ...              Univ/Inst  \n",
              "3  [[school mechanical engineering automation, Un...              Univ/Inst  \n",
              "4                  [[shenzhen universit, Univ/Inst]]              Univ/Inst  \n",
              "5  [[communal institution higher education dnipro...  Univ/Inst, Government  \n",
              "6  [[leiden universit hospital, Univ/Inst], [leid...    Univ/Inst, Hospital  \n",
              "7                [[univ colorado denver, Univ/Inst]]              Univ/Inst  \n",
              "8  [[univ alabama birmingham, Univ/Inst], [univ a...  Univ/Inst, Laboratory  \n",
              "9  [[maharishi markandeshwar institute physiother...              Univ/Inst  "
            ]
          },
          "execution_count": 218,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "affDF[0:10]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# radius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [],
      "source": [
        "def strRadiusU(string):\n",
        "    string = string.lower()\n",
        "    radius = 3\n",
        "    \n",
        "    strList = string.split()\n",
        "    indices = []\n",
        "    result = []\n",
        "\n",
        "    for i, x in enumerate(strList):\n",
        "        if is_contained('univers',x):\n",
        "            indices.append(i)\n",
        "            \n",
        "    for r0 in indices:\n",
        "        lmin =max(0,r0-radius)\n",
        "        lmax =min(r0+radius, len(strList))\n",
        "        s = strList[lmin:lmax]\n",
        "        \n",
        "        result.append(' '.join(s))\n",
        "    \n",
        "    return result "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [],
      "source": [
        "def strRadiusH(string):\n",
        "    string = string.lower()\n",
        "    radius = 3\n",
        "    \n",
        "    strList = string.split()\n",
        "    indices = []\n",
        "    result = []\n",
        "\n",
        "    for i, x in enumerate(strList):\n",
        "        if is_contained('hospital',x):\n",
        "            indices.append(i)\n",
        "            \n",
        "    for r0 in indices:\n",
        "        lmin =max(0,r0-radius-1)\n",
        "        lmax =min(r0+radius, len(strList))\n",
        "        s = strList[lmin:lmax]\n",
        "        \n",
        "        result.append(' '.join(s))\n",
        "    \n",
        "    return result "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "def strRadiusC(string):\n",
        "    string = string.lower()\n",
        "    radius = 2\n",
        "    \n",
        "    strList = string.split()\n",
        "    indices = []\n",
        "    result = []\n",
        "\n",
        "    for i, x in enumerate(strList):\n",
        "        if is_contained('clinic',x) or is_contained('klinik',x):\n",
        "            indices.append(i)\n",
        "            \n",
        "    for r0 in indices:\n",
        "        lmin =max(0,r0-radius-1)\n",
        "        lmax =min(r0+radius, len(strList))\n",
        "        s = strList[lmin:lmax]\n",
        "        \n",
        "        result.append(' '.join(s))\n",
        "    \n",
        "    return result "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [],
      "source": [
        "affiliationsSimpleN = []\n",
        "\n",
        "for i in range(len(affiliationsSimple)):\n",
        "    inner = []\n",
        "    for str in affiliationsSimple[i]:\n",
        "        if 'universit' in str:\n",
        "            for x in strRadiusU(str):\n",
        "                inner.append(x)\n",
        "        elif 'hospital' in str or 'hôpital' in str:\n",
        "            for x in strRadiusH(str):\n",
        "                inner.append(x)\n",
        "        elif 'clinic' in str or 'klinik' in str:\n",
        "            for x in strRadiusH(str):\n",
        "                inner.append(x)\n",
        "                \n",
        "        else:\n",
        "            inner.append(str)\n",
        "    \n",
        "    affiliationsSimpleN.append(inner)      \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [],
      "source": [
        "affDF['Keywords'] = affiliationsSimpleN"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UNIVS & LABS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [],
      "source": [
        "univLabs = [i for i in range(len(affDF)) if 'Laboratory' in affDF['Category'].iloc[i] \n",
        "            or 'Univ/Inst' in  affDF['Category'].iloc[i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "univLabsDF = affDF.iloc[univLabs].copy()\n",
        "univLabsDF.reset_index(inplace = True)\n",
        "univLabsDF.drop(columns = ['index'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8715203426124197"
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(univLabsDF)/len(affDF)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load files from openAIRE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "with open('dixAcadRor.pkl', 'rb') as f:\n",
        "    dixAcadRor = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "with open('dix_ror.pkl', 'rb') as f:\n",
        "    dix_ror = pickle.load(f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean/modify the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_key(key):\n",
        "    # Remove all non-alphanumeric characters except Greek letters and Chinese characters\n",
        "    modified_key = re.sub(r'[^\\w\\s,Α-Ωα-ωぁ-んァ-ン一-龯，]', '', key)\n",
        "    modified_key = re.sub(r'\\buniversit\\w*', 'universit', modified_key, flags=re.IGNORECASE)\n",
        "    modified_key = modified_key.replace(' and ', ' ')\n",
        "    return modified_key\n",
        "\n",
        "    \n",
        "def filter_dictionary_keys(dictionary):\n",
        "    filtered_dict = {}\n",
        "    for key, value in dictionary.items():\n",
        "        filtered_key = filter_key(key)\n",
        "        filtered_dict[filtered_key] = value\n",
        "    return filtered_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cleanDict(dix):\n",
        "    dix1 =  {k.replace(',', ''): v for k, v in dix.items()}\n",
        "    \n",
        "    dix1 = {replace_umlauts(key): value\n",
        "    for key, value in dix1.items()}\n",
        "    \n",
        "    dix1 = filter_dictionary_keys(dix1)\n",
        "    \n",
        "    dix2 = {}\n",
        "    \n",
        "    for key, value in dix1.items():\n",
        "        updated_key = ' '.join([word for word in key.split() if word.lower() not in stopWords])\n",
        "        dix2[updated_key] = value\n",
        "        \n",
        "    for x in list(dix2.keys()):\n",
        "        if len(x) <4:\n",
        "            del dix2[x]\n",
        "            \n",
        "    if 'universit hospital' in list(dix2.keys()):\n",
        "        del dix2['universit hospital']\n",
        "        \n",
        "    if 'universit school' in list(dix2.keys()):\n",
        "        del dix2['universit school']\n",
        "        \n",
        "    if 'ni universit' in list(dix2.keys()):\n",
        "        del dix2['ni universit']\n",
        "\n",
        "        \n",
        "    if 's v universit' in list(dix2.keys()):\n",
        "        del dix2['s v universit']\n",
        "\n",
        "    if 'k l universit' in list(dix2.keys()):\n",
        "        del dix2['k l universit']\n",
        "        \n",
        "    return dix2\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [],
      "source": [
        "dix_union = dix_ror | dixAcadRor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {},
      "outputs": [],
      "source": [
        "dix_union1 = cleanDict(dix_union)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "216341"
            ]
          },
          "execution_count": 334,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dix_union)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "182312"
            ]
          },
          "execution_count": 332,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dix_union1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {},
      "outputs": [],
      "source": [
        "def findID(name):\n",
        "    lnames = []\n",
        "    for x in list(dixAcadRor1.keys()):\n",
        "        if name.lower() in x:\n",
        "            lnames.append(x)\n",
        "    return lnames"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MATCHINGS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clean the matchings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bestSimScore(l1, l2, l3, l4, simU, simG):\n",
        "    \"\"\"\n",
        "    Finds the best match between a 'key word' and several legal names from the OpenAIRE database.\n",
        "    ---> corrects special cases in the main map that follows\n",
        "\n",
        "    Args:\n",
        "        l1: List of light affiliations.\n",
        "        l2: number of candidates.\n",
        "        l3: List of pairs.\n",
        "        l4: mult\n",
        "\n",
        "    Returns:\n",
        "        List: Resulting list containing OpenAIRE names and their similarity scores.\n",
        "    \"\"\"\n",
        "    \n",
        "    vectorizer = CountVectorizer()\n",
        "    numUniv = sum([(l1[i].lower()).count('univ') for i in range(len(l1))])\n",
        "    result = []\n",
        "    for i in range(len(l1)):\n",
        "        best = [] \n",
        "        s = l1[i]\n",
        "\n",
        "    \n",
        "        for j in range(len(l3)):\n",
        "            x = l3[j][1] \n",
        "           \n",
        "            if [x, l3[j][2]] in result:\n",
        "                    continue\n",
        "            \n",
        "            if l4[l3[j][0]] == 1:\n",
        "               \n",
        "                if  is_contained('univ', x.lower()) and  l3[j][2]> simU:\n",
        "                    result.append([x, l3[j][2]])\n",
        "                elif  l3[j][2] >simG:\n",
        "                    result.append([x, l3[j][2]])\n",
        "\n",
        "                \n",
        "              \n",
        "            elif l3[j][2] >=0.99 and (is_contained(\"univ\", x.lower()) or is_contained(\"college\", x.lower()) or  is_contained(\"center\", x.lower()) or  is_contained(\"schule\", x.lower())): # If the similarity score of a pair (s,x) was 1, we store it to results list\n",
        "                result.append([l3[j][1], 1])\n",
        "                \n",
        "            else:\n",
        "                try:\n",
        "            #        x_contains_university = is_contained(\"university\", x.lower())\n",
        "                    if not is_contained(\"univ\", x.lower()):\n",
        "                        continue  # Skip if x does not contain \"university\" or \"univ\"\n",
        "                    \n",
        "                    if (is_contained('hosp', x.lower()) and not is_contained('hosp', s)) or (not is_contained('hosp', x.lower()) and is_contained('hosp', s)):\n",
        "                        continue\n",
        "                    s_vector = vectorizer.fit_transform([s]).toarray() #Else we compute the similarity of s with the original affiiation name\n",
        "                    x_vector = vectorizer.transform([x]).toarray()\n",
        "\n",
        "                    \n",
        "\n",
        "                    # Compute similarity between the vectors\n",
        "                    similarity = cosine_similarity(x_vector, s_vector)[0][0]\n",
        "                    if similarity> 0.1:\n",
        "\n",
        "\n",
        "                        best.append([x, similarity])#(similarity+similarity2)/2])\n",
        "                except:\n",
        "                    KeyError\n",
        "                    \n",
        "        if best:\n",
        "            max_numbers = defaultdict(float)\n",
        "            for item in best:\n",
        "                string, number = item\n",
        "                max_numbers[string] = max(max_numbers[string], number)\n",
        "\n",
        "# Create a new list with the elements having the maximum number for each string\n",
        "            reduced_best = [[string, number] for string, number in best if number == max_numbers[string]]\n",
        "\n",
        "\n",
        "            reduced_best.sort(key=lambda x: x[1], reverse=True)\n",
        " \n",
        "            result = result + reduced_best\n",
        "                \n",
        "    univ_list = []\n",
        "    other_list = []\n",
        "    \n",
        "    for r in result:\n",
        "        if is_contained('univ',r[0]):\n",
        "            univ_list.append(r)\n",
        "        else:\n",
        "            other_list.append(r)\n",
        "    \n",
        "    limit =  min(numUniv, l2)\n",
        "\n",
        "    if len(univ_list)> limit:\n",
        "        result = univ_list[:limit] + other_list\n",
        "                \n",
        "    return result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Find rows with multiple mathcings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {},
      "outputs": [],
      "source": [
        "def index_multipleMatchings(df):\n",
        "    multipleMatchings = []\n",
        "    mult = []\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        result_dict = {}\n",
        "        \n",
        "        r_list = [y[3] for y in df.Pairs.iloc[i]]\n",
        "        modified_list = [item for sublist in r_list for item in sublist]\n",
        "        r = len(list(set(modified_list)))\n",
        "            \n",
        "        for t in [t[0] for t in df.Pairs.iloc[i]]:\n",
        "            key = t\n",
        "            if key in result_dict and r>1:\n",
        "                result_dict[key] += 1\n",
        "                multipleMatchings.append(i)\n",
        "                \n",
        "            else:\n",
        "                result_dict[key] = 1\n",
        "        mult.append(result_dict)\n",
        "   \n",
        "    return [list(set(multipleMatchings)), mult]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Aff_Ids(m, DF, dixOpenAIRE, simU, simG):\n",
        "    \n",
        "    \"\"\"\n",
        "    Matches affiliations in DataFrame 'DF' with names from dictionary 'dixOpenAIRE' and their openAIRE ids based on similarity scores.\n",
        "\n",
        "    Args:\n",
        "        m (int): The number of DOIs to check.\n",
        "        DF (DataFrame): The input DataFrame containing affiliation data.\n",
        "        dixOpenAIRE (dict): A dictionary of names from OpenAIRE.\n",
        "        simU (float): Similarity threshold for universities.\n",
        "        simG (float): Similarity threshold for non-universities.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: The final DataFrame with matched affiliations and their corresponding similarity scores.\n",
        "    \"\"\"\n",
        "    vectorizer = CountVectorizer()\n",
        "\n",
        "    lnamelist = list(dixOpenAIRE.keys())\n",
        "    dix = {}    # will store indeces and legalnames of organizations of the DOI { i : [legalname1, legalname2,...]}\n",
        "    deiktes = []  # stores indeces where a match is found\n",
        "    similarity_ab = [] # stores lists of similarity scores of the mathces \n",
        "    pairs = [] #  pairs[i] =  [ [s,x,t] ] where (s,x) is a match and t the corresponding similarity score\n",
        "    \n",
        "    for k in range(m):\n",
        "        similar_k = []\n",
        "        pairs_k = []\n",
        "\n",
        "\n",
        "        for s in DF['Keywords'].iloc[k]:\n",
        "\n",
        "            if s in lnamelist:\n",
        "                deiktes.append(k)\n",
        "                similarity = 1\n",
        "                similar_k.append(similarity)\n",
        "                \n",
        "                pairs_k.append((s,s,similarity,dixOpenAIRE[s]))\n",
        "\n",
        "                if k not in dix:\n",
        "                    dix[k] = [s]\n",
        "                else:\n",
        "                    dix[k].append(s)\n",
        "            else:\n",
        "\n",
        "                for x in lnamelist:\n",
        "                    \n",
        "                    if  is_contained(s, x):\n",
        "\n",
        "                        x_vector = vectorizer.fit_transform([x]).toarray()\n",
        "                        s_vector = vectorizer.transform([s]).toarray()\n",
        "\n",
        "                        # Compute similarity between the vectors\n",
        "                        similarity = cosine_similarity(x_vector, s_vector)[0][0]\n",
        "                        if similarity > min(simU, simG):\n",
        "                            if (is_contained('univ', s) and is_contained('univ', x)) and similarity > simU:\n",
        "                                similar_k.append(similarity)\n",
        "                                deiktes.append(k)\n",
        "                                pairs_k.append((s,x,similarity,dixOpenAIRE[x]))\n",
        "\n",
        "                                if k not in dix:\n",
        "                                    dix[k] = [x]\n",
        "                                else:\n",
        "                                    dix[k].append(x)\n",
        "                            elif (not is_contained('univ', s) and not is_contained('univ', x)) and similarity > simG:\n",
        "                                similar_k.append(similarity)\n",
        "                                deiktes.append(k)\n",
        "                                pairs_k.append((s,x,similarity,dixOpenAIRE[x]))\n",
        "\n",
        "                                if k not in dix:\n",
        "                                    dix[k] = [x]\n",
        "                                else:\n",
        "                                    dix[k].append(x)\n",
        "                                    \n",
        "                    elif is_contained(x, s):\n",
        "                        if (is_contained('univ', s) and is_contained('univ', x)):\n",
        "\n",
        "                            if ' and ' in s:\n",
        "                                list_s = s.split(' and ')\n",
        "                                \n",
        "                                if list_s:\n",
        "                                    for q in list_s:\n",
        "                                        if is_contained('univ', q):\n",
        "\n",
        "                                            q_vector = vectorizer.fit_transform([q]).toarray()\n",
        "                                            x_vector = vectorizer.transform([x]).toarray()\n",
        "\n",
        "                                # Compute similarity between the vectors\n",
        "                                            similarity = cosine_similarity(q_vector, x_vector)[0][0]\n",
        "                                            if similarity > simU:\n",
        "                                                similar_k.append(similarity)\n",
        "                                                deiktes.append(k)\n",
        "                                                pairs_k.append((s,x,similarity,dixOpenAIRE[x]))\n",
        "\n",
        "                                                if k not in dix:\n",
        "                                                    dix[k] = [x]\n",
        "                                                else:\n",
        "                                                    dix[k].append(x)\n",
        "                            \n",
        "                            else: \n",
        "\n",
        "                                s_vector = vectorizer.fit_transform([s]).toarray()\n",
        "                                x_vector = vectorizer.transform([x]).toarray()\n",
        "\n",
        "                                # Compute similarity between the vectors\n",
        "                                similarity = cosine_similarity(s_vector, x_vector)[0][0]\n",
        "                                if similarity > simU: #max(0.82,sim):\n",
        "                                    similar_k.append(similarity)\n",
        "                                    deiktes.append(k)\n",
        "                                    pairs_k.append((s,x,similarity, dixOpenAIRE[x]))\n",
        "\n",
        "                                    if k not in dix:\n",
        "                                        dix[k] = [x]\n",
        "                                    else:\n",
        "                                        dix[k].append(x)\n",
        "                        elif not is_contained('univ', s) and not is_contained('univ', x):\n",
        "  \n",
        "\n",
        "                            s_vector = vectorizer.fit_transform([s]).toarray()\n",
        "                            x_vector = vectorizer.transform([x]).toarray()\n",
        "\n",
        "                            # Compute similarity between the vectors\n",
        "                            similarity = cosine_similarity(s_vector, x_vector)[0][0]\n",
        "                            if similarity > simG: #max(0.82,sim):\n",
        "                                similar_k.append(similarity)\n",
        "                                deiktes.append(k)\n",
        "                                pairs_k.append((s,x,similarity,dixOpenAIRE[x]))\n",
        "\n",
        "                                if k not in dix:\n",
        "                                    dix[k] = [x]\n",
        "                                else:\n",
        "                                    dix[k].append(x)\n",
        "                            \n",
        "        similarity_ab.append(similar_k)   \n",
        "        similarity_ab = [lst for lst in similarity_ab if lst != []]\n",
        "        pairs.append(pairs_k)\n",
        "        \n",
        " \n",
        "    \n",
        "    \n",
        "## Define the new Dataframe\n",
        "    \n",
        "    affIdDF = pd.DataFrame()\n",
        "    affIdDF['Original affiliations'] = list(DF['Original Affiliations'].iloc[list(set(deiktes))])\n",
        "\n",
        "    affIdDF['Light affiliations'] = list(DF['Light Affiliations'].iloc[list(set(deiktes))])\n",
        "\n",
        "    affIdDF['Candidates for matching'] = list(DF['Keywords'].iloc[list(set(deiktes))])\n",
        "\n",
        "\n",
        "    affIdDF['Matched openAIRE names'] = list(dix.values())\n",
        "    affIdDF['# Matched orgs'] = [len(list(dix.values())[i]) for i in range(len(list(dix.values())))]\n",
        "    \n",
        "\n",
        "    affIdDF['Similarity score'] = similarity_ab\n",
        "\n",
        "    Pairs = [lst for lst in pairs if lst]\n",
        "    affIdDF['Pairs'] = Pairs\n",
        "    affIdDF['mult'] = index_multipleMatchings(affIdDF)[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Correct the matchings\n",
        "    needCheck = list(set([i for i in range(len(affIdDF)) for k in list(affIdDF['mult'].iloc[i].values()) if k>1]))\n",
        "\n",
        "\n",
        "    ready = [i for i in range(len(affIdDF)) if i not in needCheck]\n",
        "    \n",
        "   \n",
        "    best = [bestSimScore([affIdDF['Light affiliations'].iloc[i]], len(affIdDF['Candidates for matching'].iloc[i]), affIdDF['Pairs'].iloc[i],affIdDF['mult'].iloc[i], simU, simG) for i in needCheck]\n",
        "    best_o = []\n",
        "    best_s = []\n",
        "    \n",
        "    for x in best:\n",
        "        best_o.append([x[i][0]  for i in range(len(x))])\n",
        "        best_s.append([round(x[i][1],2)  for i in range(len(x))])\n",
        "    numMathced = [len(best_s[i]) for i in range(len(needCheck))]\n",
        "    \n",
        "\n",
        "    \n",
        "    dfFinal0 = (affIdDF.iloc[ready]).copy()\n",
        "    dfFinal0['index'] = ready\n",
        "    \n",
        "    dfFinal1 = (affIdDF.iloc[needCheck]).copy()\n",
        "    dfFinal1['index'] = needCheck\n",
        "    dfFinal1['Matched openAIRE names'] = best_o\n",
        "    dfFinal1['Similarity score'] = best_s\n",
        "    dfFinal1['# Matched orgs'] = numMathced\n",
        "    \n",
        "    finalDF =  pd.concat([dfFinal0, dfFinal1])\n",
        "    finalDF.set_index('index', inplace=True)\n",
        "    finalDF.sort_values('index', ascending=True, inplace = True)\n",
        "    \n",
        "    ids = [[dixOpenAIRE[x] for x in v] for v in finalDF['Matched openAIRE names']]\n",
        "    new_ror = []\n",
        "    for v in ids: \n",
        "        v1 = [item for sublist in v for item in sublist]\n",
        "        new_ror.append(list(set(v1)))\n",
        "\n",
        "    \n",
        "    numRors = [len(x) for x in new_ror]\n",
        "\n",
        "    finalDF['ROR'] = ids\n",
        "    finalDF['# unique RORs'] = numRors\n",
        "    finalDF = finalDF[~(finalDF['# Matched orgs'] == 0)]\n",
        "    \n",
        "    finalDF = finalDF.reset_index(drop=True)\n",
        "    diff = [i for i in range(len(finalDF)) if finalDF['# Matched orgs'].iloc[i]> finalDF['# unique RORs'].iloc[i]]\n",
        "    \n",
        "    for k in diff:\n",
        "        finalDF.at[k,'Matched openAIRE names']=(finalDF['Matched openAIRE names'].iloc[k])[0]\n",
        "        finalDF.at[k,'# Matched orgs']=1\n",
        "        finalDF.at[k,'Similarity score']=(finalDF['Similarity score'].iloc[k])[0]\n",
        "        finalDF.at[k,'ROR']=(finalDF['ROR'].iloc[k])[0]\n",
        "\n",
        "    perc = 100*len(finalDF)/m\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    return [perc,finalDF, affIdDF, needCheck, best]\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = Aff_Ids(len(univLabsDF), univLabsDF, dix_union1, 0.7,0.82)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77.39557739557739"
            ]
          },
          "execution_count": 337,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Output"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Excel [Affiliations' matchings]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original affiliations</th>\n",
              "      <th>Light affiliations</th>\n",
              "      <th>Candidates for matching</th>\n",
              "      <th>Matched openAIRE names</th>\n",
              "      <th># Matched orgs</th>\n",
              "      <th>Similarity score</th>\n",
              "      <th>Pairs</th>\n",
              "      <th>mult</th>\n",
              "      <th>ROR</th>\n",
              "      <th># unique RORs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>USDA, ARS, Eastern Regional Research Center, W...</td>\n",
              "      <td>usda, ars, eastern regional research center, w...</td>\n",
              "      <td>[eastern regional research center]</td>\n",
              "      <td>[eastern regional research center]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(eastern regional research center, eastern re...</td>\n",
              "      <td>{'eastern regional research center': 1}</td>\n",
              "      <td>[[https://ror.org/052v5pn20]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Department Food Technology, Faculty Science, C...</td>\n",
              "      <td>chulalongkorn universit, bangkok, thailand</td>\n",
              "      <td>[chulalongkorn universit]</td>\n",
              "      <td>[chulalongkorn universit]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(chulalongkorn universit, chulalongkorn unive...</td>\n",
              "      <td>{'chulalongkorn universit': 1}</td>\n",
              "      <td>[[https://ror.org/028wp3y58]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Presidency University,Dept Computer Science En...</td>\n",
              "      <td>presidency universit, dept computer science en...</td>\n",
              "      <td>[presidency universit]</td>\n",
              "      <td>[presidency universit]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(presidency universit, presidency universit, ...</td>\n",
              "      <td>{'presidency universit': 1}</td>\n",
              "      <td>[[https://ror.org/04xgbph11]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Department Chemistry, Texas AM University, PO ...</td>\n",
              "      <td>texas am universit, po box 30012, college stat...</td>\n",
              "      <td>[texas am universit]</td>\n",
              "      <td>[texas am universit]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(texas am universit, texas am universit, 1, [...</td>\n",
              "      <td>{'texas am universit': 1}</td>\n",
              "      <td>[[https://ror.org/01f5ytq51]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Marmara University, Faculty Health Sciences, D...</td>\n",
              "      <td>marmara universit, faculty health sciences, di...</td>\n",
              "      <td>[marmara universit, faculty health sciences]</td>\n",
              "      <td>[marmara universit]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(marmara universit, marmara universit, 1, [ht...</td>\n",
              "      <td>{'marmara universit': 1}</td>\n",
              "      <td>[[https://ror.org/02kswqa67]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Division Forensic Medicine, Graduate School Me...</td>\n",
              "      <td>division forensic medicine, tottori universit,...</td>\n",
              "      <td>[tottori universit]</td>\n",
              "      <td>[tottori universit]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(tottori universit, tottori universit, 1, [ht...</td>\n",
              "      <td>{'tottori universit': 1}</td>\n",
              "      <td>[[https://ror.org/024yc3q36]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Department Anatomy, Graduate School Medicine, ...</td>\n",
              "      <td>tottori universit, yonago, japan</td>\n",
              "      <td>[tottori universit]</td>\n",
              "      <td>[tottori universit]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(tottori universit, tottori universit, 1, [ht...</td>\n",
              "      <td>{'tottori universit': 1}</td>\n",
              "      <td>[[https://ror.org/024yc3q36]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Ted Rogers School Information Technology Manag...</td>\n",
              "      <td>toronto metropolitan universit, toronto, on, c...</td>\n",
              "      <td>[toronto metropolitan universit]</td>\n",
              "      <td>[universit toronto]</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.75]</td>\n",
              "      <td>[(toronto metropolitan universit, metropolitan...</td>\n",
              "      <td>{'toronto metropolitan universit': 2}</td>\n",
              "      <td>[[https://ror.org/03dbr7087]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Information Science Department, Georgian Colle...</td>\n",
              "      <td>georgian college, barrie, on, canada</td>\n",
              "      <td>[georgian college]</td>\n",
              "      <td>[georgian college]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(georgian college, georgian college, 1, [http...</td>\n",
              "      <td>{'georgian college': 1}</td>\n",
              "      <td>[[https://ror.org/04s2jm085]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Department Chemical Engineering, Curtin Univer...</td>\n",
              "      <td>curtin universit, gpo box u1987, perth, wester...</td>\n",
              "      <td>[curtin universit]</td>\n",
              "      <td>[curtin universit]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(curtin universit, curtin universit, 1, [http...</td>\n",
              "      <td>{'curtin universit': 1}</td>\n",
              "      <td>[[https://ror.org/02n415q13]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>State Key Laboratory Fine Chemicals, Key Labor...</td>\n",
              "      <td>state key laboratory fine chemicals, dalian un...</td>\n",
              "      <td>[dalian universit technology, state key labora...</td>\n",
              "      <td>[dalian universit technology]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(dalian universit technology, dalian universi...</td>\n",
              "      <td>{'dalian universit technology': 1}</td>\n",
              "      <td>[[https://ror.org/023hj5876]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Laboratory Clinical Investigation, National In...</td>\n",
              "      <td>national institute allergy infectious diseases...</td>\n",
              "      <td>[national institutes health, national institut...</td>\n",
              "      <td>[national institutes health, national institut...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>[(national institutes health, national institu...</td>\n",
              "      <td>{'national institutes health': 1, 'national in...</td>\n",
              "      <td>[[https://ror.org/01cwqze88], [https://ror.org...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Tulane Regional Primate Research Center, Tulan...</td>\n",
              "      <td>tulane regional primate research center, tulan...</td>\n",
              "      <td>[tulane regional primate research center, tula...</td>\n",
              "      <td>[tulane universit]</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.53]</td>\n",
              "      <td>[(tulane universit health sciences, universit ...</td>\n",
              "      <td>{'tulane universit health sciences': 3}</td>\n",
              "      <td>[[https://ror.org/04vmvtb21]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>University Porto</td>\n",
              "      <td>universit porto</td>\n",
              "      <td>[universit porto]</td>\n",
              "      <td>[universit porto]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(universit porto, universit porto, 1, [https:...</td>\n",
              "      <td>{'universit porto': 1}</td>\n",
              "      <td>[[https://ror.org/043pwc612]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Centre Recherches Politiques Sciences Po, Inst...</td>\n",
              "      <td>centre recherches politiques sciences po, inst...</td>\n",
              "      <td>[institut detudes politiques paris paris franc...</td>\n",
              "      <td>[centre recherches politiques sciences po]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[(centre recherches politiques sciences po, ce...</td>\n",
              "      <td>{'centre recherches politiques sciences po': 1}</td>\n",
              "      <td>[[https://ror.org/0266y7j75]]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Original affiliations  \\\n",
              "15  USDA, ARS, Eastern Regional Research Center, W...   \n",
              "16  Department Food Technology, Faculty Science, C...   \n",
              "17  Presidency University,Dept Computer Science En...   \n",
              "18  Department Chemistry, Texas AM University, PO ...   \n",
              "19  Marmara University, Faculty Health Sciences, D...   \n",
              "20  Division Forensic Medicine, Graduate School Me...   \n",
              "21  Department Anatomy, Graduate School Medicine, ...   \n",
              "22  Ted Rogers School Information Technology Manag...   \n",
              "23  Information Science Department, Georgian Colle...   \n",
              "24  Department Chemical Engineering, Curtin Univer...   \n",
              "25  State Key Laboratory Fine Chemicals, Key Labor...   \n",
              "26  Laboratory Clinical Investigation, National In...   \n",
              "27  Tulane Regional Primate Research Center, Tulan...   \n",
              "28                                   University Porto   \n",
              "29  Centre Recherches Politiques Sciences Po, Inst...   \n",
              "\n",
              "                                   Light affiliations  \\\n",
              "15  usda, ars, eastern regional research center, w...   \n",
              "16         chulalongkorn universit, bangkok, thailand   \n",
              "17  presidency universit, dept computer science en...   \n",
              "18  texas am universit, po box 30012, college stat...   \n",
              "19  marmara universit, faculty health sciences, di...   \n",
              "20  division forensic medicine, tottori universit,...   \n",
              "21                   tottori universit, yonago, japan   \n",
              "22  toronto metropolitan universit, toronto, on, c...   \n",
              "23               georgian college, barrie, on, canada   \n",
              "24  curtin universit, gpo box u1987, perth, wester...   \n",
              "25  state key laboratory fine chemicals, dalian un...   \n",
              "26  national institute allergy infectious diseases...   \n",
              "27  tulane regional primate research center, tulan...   \n",
              "28                                    universit porto   \n",
              "29  centre recherches politiques sciences po, inst...   \n",
              "\n",
              "                              Candidates for matching  \\\n",
              "15                 [eastern regional research center]   \n",
              "16                          [chulalongkorn universit]   \n",
              "17                             [presidency universit]   \n",
              "18                               [texas am universit]   \n",
              "19       [marmara universit, faculty health sciences]   \n",
              "20                                [tottori universit]   \n",
              "21                                [tottori universit]   \n",
              "22                   [toronto metropolitan universit]   \n",
              "23                                 [georgian college]   \n",
              "24                                 [curtin universit]   \n",
              "25  [dalian universit technology, state key labora...   \n",
              "26  [national institutes health, national institut...   \n",
              "27  [tulane regional primate research center, tula...   \n",
              "28                                  [universit porto]   \n",
              "29  [institut detudes politiques paris paris franc...   \n",
              "\n",
              "                               Matched openAIRE names  # Matched orgs  \\\n",
              "15                 [eastern regional research center]               1   \n",
              "16                          [chulalongkorn universit]               1   \n",
              "17                             [presidency universit]               1   \n",
              "18                               [texas am universit]               1   \n",
              "19                                [marmara universit]               1   \n",
              "20                                [tottori universit]               1   \n",
              "21                                [tottori universit]               1   \n",
              "22                                [universit toronto]               1   \n",
              "23                                 [georgian college]               1   \n",
              "24                                 [curtin universit]               1   \n",
              "25                      [dalian universit technology]               1   \n",
              "26  [national institutes health, national institut...               2   \n",
              "27                                 [tulane universit]               1   \n",
              "28                                  [universit porto]               1   \n",
              "29         [centre recherches politiques sciences po]               1   \n",
              "\n",
              "   Similarity score                                              Pairs  \\\n",
              "15              [1]  [(eastern regional research center, eastern re...   \n",
              "16              [1]  [(chulalongkorn universit, chulalongkorn unive...   \n",
              "17              [1]  [(presidency universit, presidency universit, ...   \n",
              "18              [1]  [(texas am universit, texas am universit, 1, [...   \n",
              "19              [1]  [(marmara universit, marmara universit, 1, [ht...   \n",
              "20              [1]  [(tottori universit, tottori universit, 1, [ht...   \n",
              "21              [1]  [(tottori universit, tottori universit, 1, [ht...   \n",
              "22           [0.75]  [(toronto metropolitan universit, metropolitan...   \n",
              "23              [1]  [(georgian college, georgian college, 1, [http...   \n",
              "24              [1]  [(curtin universit, curtin universit, 1, [http...   \n",
              "25              [1]  [(dalian universit technology, dalian universi...   \n",
              "26           [1, 1]  [(national institutes health, national institu...   \n",
              "27           [0.53]  [(tulane universit health sciences, universit ...   \n",
              "28              [1]  [(universit porto, universit porto, 1, [https:...   \n",
              "29              [1]  [(centre recherches politiques sciences po, ce...   \n",
              "\n",
              "                                                 mult  \\\n",
              "15            {'eastern regional research center': 1}   \n",
              "16                     {'chulalongkorn universit': 1}   \n",
              "17                        {'presidency universit': 1}   \n",
              "18                          {'texas am universit': 1}   \n",
              "19                           {'marmara universit': 1}   \n",
              "20                           {'tottori universit': 1}   \n",
              "21                           {'tottori universit': 1}   \n",
              "22              {'toronto metropolitan universit': 2}   \n",
              "23                            {'georgian college': 1}   \n",
              "24                            {'curtin universit': 1}   \n",
              "25                 {'dalian universit technology': 1}   \n",
              "26  {'national institutes health': 1, 'national in...   \n",
              "27            {'tulane universit health sciences': 3}   \n",
              "28                             {'universit porto': 1}   \n",
              "29    {'centre recherches politiques sciences po': 1}   \n",
              "\n",
              "                                                  ROR  # unique RORs  \n",
              "15                      [[https://ror.org/052v5pn20]]              1  \n",
              "16                      [[https://ror.org/028wp3y58]]              1  \n",
              "17                      [[https://ror.org/04xgbph11]]              1  \n",
              "18                      [[https://ror.org/01f5ytq51]]              1  \n",
              "19                      [[https://ror.org/02kswqa67]]              1  \n",
              "20                      [[https://ror.org/024yc3q36]]              1  \n",
              "21                      [[https://ror.org/024yc3q36]]              1  \n",
              "22                      [[https://ror.org/03dbr7087]]              1  \n",
              "23                      [[https://ror.org/04s2jm085]]              1  \n",
              "24                      [[https://ror.org/02n415q13]]              1  \n",
              "25                      [[https://ror.org/023hj5876]]              1  \n",
              "26  [[https://ror.org/01cwqze88], [https://ror.org...              2  \n",
              "27                      [[https://ror.org/04vmvtb21]]              1  \n",
              "28                      [[https://ror.org/043pwc612]]              1  \n",
              "29                      [[https://ror.org/0266y7j75]]              1  "
            ]
          },
          "execution_count": 315,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[1][15:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [],
      "source": [
        "affsMatch = result[1][['Original affiliations','Matched openAIRE names', 'ROR']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {},
      "outputs": [],
      "source": [
        "affsMatch.to_excel('affilMatch.xlsx', index=False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Εxcel [Dois' matchibgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict_aff_open = {x: y for x, y in zip(result[1]['Original affiliations'], result[1]['Matched openAIRE names'])}\n",
        "dict_aff_id = {x: y for x, y in zip(result[1]['Original affiliations'], result[1]['ROR'])}\n",
        "#dict_aff_score = {x: y for x, y in zip(result[1]['Original affiliations'], result[1]['Similarity score'])}\n",
        "\n",
        "dict_aff_score = {}\n",
        "for i in range(len(result[1])):\n",
        "    if type(result[1]['Similarity score'].iloc[i]) == list:\n",
        "        dict_aff_score[result[1]['Original affiliations'].iloc[i]] = result[1]['Similarity score'].iloc[i]\n",
        "    else:\n",
        "        dict_aff_score[result[1]['Original affiliations'].iloc[i]] = [result[1]['Similarity score'].iloc[i]]\n",
        "        \n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {},
      "outputs": [],
      "source": [
        "pids = []\n",
        "for i in range(len(doiDF)):\n",
        "    pidsi = []\n",
        "    for aff in doiDF['Unique affiliations'].iloc[i]:\n",
        "        if aff in list(dict_aff_id.keys()):\n",
        "            pidsi = pidsi + dict_aff_id[aff]\n",
        "        elif 'unmatched organization(s)' not in pidsi:\n",
        "            pidsi = pidsi + ['unmatched organization(s)']\n",
        "    pids.append(pidsi)\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {},
      "outputs": [],
      "source": [
        "names = []\n",
        "for i in range(len(doiDF)):\n",
        "    namesi = []\n",
        "    for aff in doiDF['Unique affiliations'].iloc[i]:\n",
        "        if aff in list(dict_aff_open.keys()):\n",
        "            try:\n",
        "                namesi = namesi + dict_aff_open[aff]\n",
        "            except TypeError:\n",
        "                namesi = namesi + [dict_aff_open[aff]]\n",
        "            \n",
        "    names.append(namesi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = []\n",
        "for i in range(len(doiDF)):\n",
        "    scoresi = []\n",
        "    for aff in doiDF['Unique affiliations'].iloc[i]:\n",
        "        if aff in list(dict_aff_score.keys()):\n",
        "            scoresi = scoresi +  dict_aff_score[aff]\n",
        "            \n",
        "    scores.append(scoresi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {},
      "outputs": [],
      "source": [
        "doiDF['Matched openAIRE names'] = names\n",
        "doiDF['ROR'] = pids\n",
        "doiDF['Scores'] = scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {},
      "outputs": [],
      "source": [
        "unmatched = [i for i in range(len(doiDF)) if doiDF['Matched openAIRE names'].iloc[i] == []]\n",
        "        \n",
        "matched = [i for i in range(len(doiDF))  if i not in unmatched]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {},
      "outputs": [],
      "source": [
        "finalDF0 =  doiDF.iloc[matched].copy()\n",
        "finalDF0.reset_index(inplace = True)\n",
        "\n",
        "finalDF = finalDF0[['DOI',\"Unique affiliations\",'Matched openAIRE names','ROR', 'Scores']].copy()\n",
        "\n",
        "def update_Z(row):\n",
        "    if len(row['ROR']) == 0 or len(row['Scores']) == 0:\n",
        "        return []\n",
        "    \n",
        "    new_Z = []\n",
        "    for ror, score in zip(row['ROR'], row['Scores']):\n",
        "        entry = {'RORid': ror, 'Confidence': score}\n",
        "        new_Z.append(entry)\n",
        "    return new_Z\n",
        "\n",
        "matching = finalDF.apply(update_Z, axis=1)\n",
        "\n",
        "finalDF['Matchings'] = matching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {},
      "outputs": [],
      "source": [
        "finalDF_short = finalDF[['Unique affiliations','Matched openAIRE names','Scores']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {},
      "outputs": [],
      "source": [
        "finalDF_short.to_excel('doisMatch.xlsx', index=False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. JSON [Final output]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "doiDF_output = finalDF[['DOI','Matchings']]\n",
        "\n",
        "doisMatch = doiDF_output.to_json(orient='records', lines=True)\n",
        "\n",
        "# Save the JSON to a file\n",
        "with open('doisMatch.json', 'w') as f:\n",
        "    f.write(doisMatch)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "name": "beginners_kit_zeppelin_notebook"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
