{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Import packages\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "##import unicodedata\n",
        "import html\n",
        "import sys\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import pickle\n",
        "\n",
        "## Import Levenshtein\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "## Import functions -- main algorithm\n",
        "\n",
        "sys.path.append('..')\n",
        "\n",
        "from create_input import *\n",
        "from affro import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import ROR-related dictionaries \n",
        "\n",
        "with open('../dictionaries/dix_acad.pkl', 'rb') as f:\n",
        "    dix_acad = pickle.load(f)\n",
        "\n",
        "with open('../dictionaries/dix_mult.pkl', 'rb') as f:\n",
        "    dix_mult = pickle.load(f)\n",
        "\n",
        "with open('../dictionaries/dix_city.pkl', 'rb') as f:\n",
        "    dix_city = pickle.load(f)\n",
        "    \n",
        "with open('../dictionaries/dix_country.pkl', 'rb') as f:\n",
        "    dix_country = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Upload json file\n",
        "\n",
        "file = 'sample.json'\n",
        "\n",
        "crossref_df = pd.read_json(file, orient='records')\n",
        "\n",
        "## And... let the cleaning begin. \n",
        "\n",
        "authors = [i for i in range(len(crossref_df)) if 'author'  in crossref_df['items'][i]]\n",
        "\n",
        "crossref_auth = crossref_df.iloc[authors].copy()\n",
        "\n",
        "crossref_auth.reset_index(inplace= True)\n",
        "crossref_auth.drop(columns = ['index'], inplace = True)\n",
        "\n",
        "crossref_auth.loc[:, 'DOI'] = crossref_auth['items'].apply(lambda x: x['DOI'])\n",
        "crossref_auth.loc[:,'authors'] = crossref_auth['items'].apply(lambda x: x['author'])\n",
        "\n",
        "def getAff(k):\n",
        "   return [crossref_auth['authors'][k][j]['affiliation'] for j in range(len(crossref_auth['authors'][k]))]\n",
        "    \n",
        "affiliations = [getAff(k) for k in range(len(crossref_auth))]\n",
        "\n",
        "crossref_auth.loc[:,'affiliations'] = affiliations\n",
        "\n",
        "\n",
        "## Clean 'empty' affiliations\n",
        "\n",
        "possible_empty_aff = []\n",
        "\n",
        "for k in range(len(crossref_auth)):\n",
        "    if len(crossref_auth['affiliations'][k][0]) == 0:\n",
        "        possible_empty_aff.append(k)\n",
        "        \n",
        "non_empty_aff = []\n",
        "\n",
        "for k in possible_empty_aff:\n",
        "    for j in range(len(crossref_auth['affiliations'].iloc[k])):\n",
        "        if len(crossref_auth['affiliations'].iloc[k][j]) != 0:\n",
        "            non_empty_aff.append(k)\n",
        "    \n",
        "final_emptyy_aff =  [x for x in possible_empty_aff if x not in non_empty_aff] \n",
        "final_non_empty_aff = [x for x in range(len(crossref_auth)) if x not in final_emptyy_aff]\n",
        "\n",
        "\n",
        "# doi_df: crossref_auth subdataframe with nonpempty affiliation lists\n",
        "\n",
        "doi_df = crossref_auth.iloc[final_non_empty_aff].copy()\n",
        "doi_df.reset_index(inplace = True)\n",
        "doi_df.drop(columns = ['index'], inplace = True)\n",
        "\n",
        "# (still some cleaning: cases with empty brackets [{}])\n",
        "\n",
        "empty_brackets = [k for k in range(len(doi_df)) if len(doi_df['affiliations'][k][0]) != 0 and doi_df['affiliations'][k][0][0] == {}]\n",
        "doi_df.iloc[empty_brackets]\n",
        "doi_df.drop(empty_brackets, inplace = True)\n",
        "\n",
        "doi_df.reset_index(inplace = True)\n",
        "doi_df.drop(columns = ['index'], inplace = True)\n",
        "\n",
        "\n",
        "# 1. \"Unique\" affiliations --- number of unique affiliations\n",
        "\n",
        "unique_aff = []\n",
        "error_indices =[] # New list to store error indices\n",
        "for i in range(len(doi_df)):\n",
        "    try:\n",
        "        unique_aff.append(list(set([x[0] for x in [list(d.values()) for d in [item for sublist in doi_df['affiliations'].iloc[i] for item in sublist if sublist !=[{}] and item !={}]]])))\n",
        "    except TypeError:\n",
        "        print(\"Error occurred for i =\", i)\n",
        "        error_indices.append(i)  # Save the index where the error occurred\n",
        "    #except IndexError:\n",
        "     #   print(\"IndexError occurred for i =\", i)\n",
        "      #  error_indices.append(i)  # Save the index where the IndexError occurred\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "doi_df.drop(error_indices, inplace = True)\n",
        "doi_df.reset_index(inplace = True)\n",
        "doi_df.drop(columns = ['index'], inplace = True)\n",
        "\n",
        "doi_df.loc[:,'unique_aff'] = unique_aff\n",
        "\n",
        "#num_unique_aff = [len(doi_df['unique_aff'].iloc[i]) for i in range(len(doi_df))]\n",
        "\n",
        "#doi_df.loc[:,'# unique_aff'] = num_unique_aff\n",
        "\n",
        "new_aff0 = []\n",
        "\n",
        "for k in range(len(doi_df)):\n",
        "    \n",
        "    L2 = []\n",
        "    for s1 in doi_df['unique_aff'].iloc[k]:\n",
        "        is_substring = False\n",
        "        for s2 in doi_df['unique_aff'].iloc[k]:\n",
        "            if s1 != s2 and s1 in s2:\n",
        "                is_substring = True\n",
        "                break\n",
        "        if not is_substring:\n",
        "            L2.append(s1)\n",
        "    new_aff0.append(L2)\n",
        "    \n",
        "new_aff_list = [list(set(new_aff0[k])) for k in range(len(new_aff0))]\n",
        "doi_df['Unique affiliations'] = new_aff_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "academia_df = create_df_algorithm(doi_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(doi_df) > 0:\n",
        "    academia_df = create_df_algorithm(doi_df)\n",
        "else:\n",
        "    academia_df= pd.DataFrame(columns = ['Original affiliations', 'Light affiliations', 'Keywords', 'Dictionary', 'Category'])\n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(academia_df)>0:   \n",
        "    result = Aff_Ids(len(academia_df), academia_df,dix_acad, dix_mult, dix_city, dix_country, 0.65,0.82)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# prepare the outputs \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(result)>0:\n",
        "\n",
        "    affs_match = result[['Original affiliations','Matched organizations', 'unique ROR']]\n",
        "\n",
        "    dict_aff_open = {x: y for x, y in zip(result['Original affiliations'], result['Matched organizations'])}\n",
        "    dict_aff_id = {x: y for x, y in zip(result['Original affiliations'], result['unique ROR'])}\n",
        "    #dict_aff_score = {x: y for x, y in zip(result['Original affiliations'], result['Similarity score'])}\n",
        "\n",
        "    dict_aff_score = {}\n",
        "    for i in range(len(result)):\n",
        "        if type(result['Similarity score'].iloc[i]) == list:\n",
        "            dict_aff_score[result['Original affiliations'].iloc[i]] = result['Similarity score'].iloc[i]\n",
        "        else:\n",
        "            dict_aff_score[result['Original affiliations'].iloc[i]] = [result['Similarity score'].iloc[i]]\n",
        "            \n",
        "\n",
        "    pids = []\n",
        "    for i in range(len(doi_df)):\n",
        "        pidsi = []\n",
        "        for aff in doi_df['Unique affiliations'].iloc[i]:\n",
        "            if aff in list(dict_aff_id.keys()):\n",
        "                pidsi = pidsi + dict_aff_id[aff]\n",
        "        # elif 'unmatched organization(s)' not in pidsi:\n",
        "        #     pidsi = pidsi + ['unmatched organization(s)']\n",
        "        pids.append(pidsi)\n",
        "                \n",
        "                \n",
        "    names = []\n",
        "    for i in range(len(doi_df)):\n",
        "        namesi = []\n",
        "        for aff in doi_df['Unique affiliations'].iloc[i]:\n",
        "            if aff in list(dict_aff_open.keys()):\n",
        "                try:\n",
        "                    namesi = namesi + dict_aff_open[aff]\n",
        "                except TypeError:\n",
        "                    namesi = namesi + [dict_aff_open[aff]]\n",
        "                \n",
        "        names.append(namesi)\n",
        "        \n",
        "    scores = []\n",
        "    for i in range(len(doi_df)):\n",
        "        scoresi = []\n",
        "        for aff in doi_df['Unique affiliations'].iloc[i]:\n",
        "            if aff in list(dict_aff_score.keys()):\n",
        "                scoresi = scoresi +  dict_aff_score[aff]\n",
        "                \n",
        "        scores.append(scoresi)\n",
        "        \n",
        "        \n",
        "    doi_df['Matched organizations'] = names\n",
        "    doi_df['ROR'] = pids\n",
        "    doi_df['Scores'] = scores\n",
        "\n",
        "\n",
        "    unmatched = [i for i in range(len(doi_df)) if doi_df['Matched organizations'].iloc[i] == []]\n",
        "            \n",
        "    matched = [i for i in range(len(doi_df))  if i not in unmatched]\n",
        "\n",
        "\n",
        "    final_df0 =  doi_df.iloc[matched].copy()\n",
        "    final_df0.reset_index(inplace = True)\n",
        "\n",
        "    final_df = final_df0[['DOI',\"Unique affiliations\",'Matched organizations','ROR', 'Scores']].copy()\n",
        "\n",
        "    def update_Z(row):\n",
        "        if len(row['ROR']) == 0 or len(row['Scores']) == 0:\n",
        "            return []\n",
        "        \n",
        "        new_Z = []\n",
        "        for ror, score in zip(row['ROR'], row['Scores']):\n",
        "            entry = {'RORid': ror, 'Confidence': score}\n",
        "            new_Z.append(entry)\n",
        "        return new_Z\n",
        "\n",
        "    matching = final_df.apply(update_Z, axis=1)\n",
        "\n",
        "    final_df['Matchings'] = matching\n",
        "\n",
        "    final_df_short = final_df[['Unique affiliations','Matched organizations','ROR','Scores']]\n",
        "\n",
        "    # 3. JSON [Final output]\n",
        "\n",
        "\n",
        "    doi_df_output = final_df[['DOI','Matchings']]\n",
        "\n",
        "    dois_match = doi_df_output.to_json(orient='records', lines=True)\n",
        "\n",
        "    # Save the JSON to a file\n",
        "    with open('dois_match.json', 'w') as f:\n",
        "        f.write(dois_match)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "affs_match.to_csv('affs_match.csv', index=False) \n",
        "final_df_short.to_csv('dois_match.csv', index=False) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "name": "beginners_kit_zeppelin_notebook"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
